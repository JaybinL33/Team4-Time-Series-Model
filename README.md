# 시계열 모델 프로젝트 (Team 4)

이 프로젝트는 시계열 데이터 분석 및 예측을 위한 **팀 프로젝트 템플릿**입니다. ARIMA, SARIMA 등 전통적인 통계 기법부터 머신러닝(Random Forest, XGBoost), 딥러닝(ANN, LSTM) 모델까지 다양한 시계열 분석 방법론을 다룹니다. **프로젝트 참여자**가 각 방법론의 핵심 과정을 이해하고 자신의 데이터에 쉽게 적용해볼 수 있도록 단계별 설명과 실행 가능한 코드를 제공하는 것을 목표로 합니다.

## 프로젝트 목표
- 시계열 데이터의 기본적인 탐색 및 전처리 방법 학습
- 다양한 시계열 분석 및 예측 모델(통계, 머신러닝, 딥러닝)의 구현 및 비교 평가
- 각 모델의 가정, 장단점, 적용 시나리오 이해
- 단계별 코드와 설명을 통해 실습 및 응용 능력 향상

본 프로젝트는 **Anaconda/Miniconda** 환경을 사용하여 모든 팀원이 **동일한 Python 버전(3.11) 및 필수 패키지 환경**을 갖도록 구성되었습니다. (`environment.yml` 파일 참조)

## 시계열 프로젝트 진행 방식 (템플릿 활용 가이드)

각 템플릿 노트북은 일반적인 시계열 분석 및 예측 프로젝트 흐름을 따르며, 다음과 같은 단계로 구성되어 있습니다:

1.  **문제 정의 및 목표 설정**: 분석/예측 대상, 목표, 평가 지표 등을 명확히 합니다.
2.  **데이터 탐색 및 전처리**: 데이터를 로드하고 시각화하여 특성을 파악하며, 결측치 처리, 정상성 확보(필요시), 특성 엔지니어링, 스케일링 등 모델링에 필요한 데이터를 준비합니다.
3.  **모델 선택 및 구현**: 해당 템플릿의 주제가 되는 모델(ARIMA, LSTM 등)을 선택하고, 파라미터를 설정하여 모델을 구축합니다.
4.  **모델 학습 및 평가**: 준비된 데이터로 모델을 학습시키고, 검증/테스트 데이터를 사용하여 성능(RMSE, MAE, R², 정확도, F1 등)을 평가합니다. 필요시 잔차 분석 등을 통해 모델의 적합성을 진단합니다.
5.  **모델 비교 (해당시)**: 여러 모델 구조나 파라미터를 실험한 경우 성능을 비교하여 최적 모델을 선정합니다.
6.  **결과 해석 및 인사이트 도출**: 최종 모델의 성능을 해석하고, 예측 결과를 분석하며 데이터와 모델에 대한 인사이트를 정리합니다. (필요시 미래 예측 수행)

## 제공된 템플릿 노트북

본 프로젝트는 다양한 시계열 분석 방법론에 맞는 Jupyter Notebook (`.ipynb`) 템플릿을 제공합니다. 각 노트북은 독립적으로 실행 가능하며, 특정 분석 기법에 집중합니다.

1.  **`time_series_basic.ipynb`**: 시계열 데이터의 기본적인 특성(추세, 계절성, 정상성 등)을 탐색하고 시각화하며, 간단한 베이스라인 예측 모델(Naive, Linear Trend 등)을 다룹니다.
2.  **`time_series_arima.ipynb`**: 전통적인 통계 기반 시계열 모델인 ARIMA 및 계절성을 고려한 SARIMA 모델의 구축, 파라미터 추정(ACF/PACF 분석 또는 Auto ARIMA 활용), 예측 및 평가 과정을 다룹니다.
3.  **`time_series_ml.ipynb`**: 시계열 데이터를 특성 기반의 회귀 문제로 변환하여 머신러닝 모델(Linear Regression, Random Forest, XGBoost 등)을 적용하는 방법을 다룹니다. 특성 엔지니어링(lag, rolling, date features)이 중요한 부분을 차지합니다.
4.  **`time_series_lstm.ipynb`**: 순서 정보와 장기 의존성 학습에 강점이 있는 LSTM(Long Short-Term Memory) 딥러닝 모델을 이용한 시계열 예측 방법을 다룹니다. 데이터 스케일링 및 시퀀스 변환 과정이 포함됩니다.
5.  **`time_series_ann.ipynb`**: 기본적인 인공신경망(ANN/MLP)을 시계열 예측에 적용하는 방법을 다룹니다. 특성 엔지니어링을 통해 생성된 벡터를 입력으로 사용합니다.
6.  **`time_series_classification.ipynb`**: 시계열 데이터를 윈도우 기반 특성으로 변환하여 특정 상태나 이벤트를 분류(Classification)하는 문제를 다룹니다. (예: 정상/비정상 상태 분류)

## 구현된 주요 모델 소개

각 템플릿에서 다루는 주요 모델은 다음과 같습니다:

- **통계 모델**: ARIMA, SARIMA
- **머신러닝 모델**: Linear Regression, Random Forest Regressor, XGBoost Regressor (회귀 문제), RandomForest Classifier, XGBoost Classifier, SVC (분류 문제)
- **딥러닝 모델**: ANN (MLP), LSTM
- **기본/베이스라인 모델**: Naive, Linear Trend, Moving Average, Seasonal Naive

## 데이터셋

- **기본 경로**: 템플릿들은 기본적으로 `data/raw/your_data.csv` 파일을 로드하도록 설정되어 있습니다. 사용자는 이 경로에 자신의 데이터를 위치시키거나 코드 내 `DATA_PATH` 변수를 수정해야 합니다.
- **처리된 데이터**: 일부 템플릿은 전처리된 데이터를 `data/processed/` 폴더에 저장할 수 있습니다.
- **시각화 결과**: 생성된 그래프는 `plots/` 폴더에 저장됩니다.

## 필수 요구사항

*   **Anaconda 또는 Miniconda 설치**
*   **Git**
*   **(선택) CUDA 지원 GPU**: 딥러닝 모델(LSTM, ANN) 학습 속도 향상

## 시작하기

프로젝트 환경 설정 및 실행 방법은 이전과 동일합니다. (`scripts` 폴더 내 `setup`, `update`, `start` 스크립트 사용)

**Windows 사용자:**

1.  저장소 복제/다운로드 및 폴더 이동
2.  초기 설정: `scripts/setup.bat` 실행
3.  환경 업데이트 (필요시): `scripts/update.bat` 실행
4.  Jupyter Lab 시작: `scripts/start.bat` 실행

**macOS / Linux 사용자:**

1.  저장소 복제/다운로드 및 폴더 이동
2.  스크립트 실행 권한 부여: `chmod +x scripts/*.sh`
3.  초기 설정: `scripts/setup.sh` 실행
4.  환경 업데이트 (필요시): `scripts/update.sh` 실행
5.  Jupyter Lab 시작: `scripts/start.sh` 실행

## 템플릿 노트북 사용하기

Jupyter Lab이 실행되면 `notebooks/` 폴더로 이동하여 원하는 `.ipynb` 템플릿 파일을 열어 사용합니다.

- 각 노트북 상단의 **사용자 입력 파라미터 설정** 셀에서 자신의 데이터 경로, 컬럼명, 분석 파라미터 등을 수정합니다.
- 셀을 순차적으로 실행하며 코드와 마크다운 설명을 참고하여 분석을 진행합니다.
- 필요에 따라 코드를 수정하거나 새로운 분석 단계를 추가하여 활용할 수 있습니다.

## 프로젝트 구조

```
Team4-Time-Series-Model/
├── data/                 # 데이터 파일 저장
│   ├── raw/              # 원시 데이터 (your_data.csv 위치)
│   └── processed/        # 처리된 데이터 저장 (선택적)
├── notebooks/            # Jupyter 노트북 템플릿 (.ipynb)
│   ├── time_series_basic.ipynb
│   ├── time_series_arima.ipynb
│   ├── time_series_ml.ipynb
│   ├── time_series_lstm.ipynb
│   ├── time_series_ann.ipynb
│   └── time_series_classification.ipynb
├── plots/                # 시각화 결과물 저장
├── scripts/              # 실행 스크립트 (setup, update, start .bat/.sh)
├── .gitignore            # Git 제외 파일 설정
├── environment.yml       # Conda 환경 설정 파일
└── README.md             # 프로젝트 설명 문서 (본 문서)
```

## 템플릿 선택 가이드

분석하려는 데이터와 문제 유형에 따라 적합한 템플릿을 선택하세요:

1.  **`time_series_basic.ipynb`**: 시계열 데이터의 기본적인 특성(추세, 계절성, 정상성)을 파악하고 싶을 때.
2.  **`time_series_arima.ipynb`**: 데이터의 자기상관성이 뚜렷하고, 통계적으로 엄밀한 모델링을 선호할 때 (단변량 데이터 중심).
3.  **`time_series_ml.ipynb`**: 다양한 외부 특성(날짜 정보, 다른 변수 등)을 활용하여 예측 성능을 높이고 싶을 때, 비선형 관계가 예상될 때.
4.  **`time_series_lstm.ipynb`**: 데이터의 장기적인 패턴이나 복잡한 시간적 의존성을 모델링하고 싶을 때, 데이터 양이 비교적 많을 때.
5.  **`time_series_ann.ipynb`**: 간단한 딥러닝 모델로 시계열 예측을 시도해보고 싶을 때 (ML과 LSTM의 중간적 복잡도).
6.  **`time_series_classification.ipynb`**: 시계열 패턴을 기반으로 특정 상태나 이벤트를 분류하는 문제가 주어졌을 때.

## 팀 내 협업 가이드

### 브랜치 전략
- **브랜치 네이밍 규칙**:
  - `main`: 최종 배포용 코드 (안정적인 버전)
  - `develop`: 개발 중인 코드를 통합하는 브랜치
  - `feature/기능명`: 새로운 기능 개발 (예: `feature/데이터전처리`, `feature/arima모델구현`)
  - `fix/이슈명`: 버그 수정 (예: `fix/예측오류수정`, `fix/그래프렌더링문제`)
  - `refactor/설명`: 코드 리팩토링 (예: `refactor/변수명표준화`)
- **작업 흐름**:
  1. `develop` 브랜치에서 새 작업용 브랜치 생성 (`feature/기능명`)
  2. 개발 완료 후 `develop`으로 병합 (PR 또는 직접 병합)
  3. 테스트 완료된 `develop` 내용을 주기적으로 `main`에 병합

### Pull Request(PR) 프로세스
1. **PR 생성**: 작업 브랜치에서 대상 브랜치(보통 `develop`)로 PR 생성
2. **설명 작성**: 변경 내용, 목적, 테스트 결과 등을 명확히 기술
3. **리뷰 요청**: 필요시 팀원에게 코드 리뷰 요청
4. **피드백 반영**: 리뷰 의견을 반영하여 수정
5. **병합**: 승인 후 대상 브랜치로 병합 (Merge 또는 Squash and merge)

### 충돌(Conflict) 해결 방법
1. **예방책**: 
   - 자주 `develop` 브랜치의 최신 변경사항을 자신의 브랜치로 병합(`git merge develop`)
   - 작업 영역을 팀원과 사전에 조율하여 동일 파일 동시 수정 최소화
2. **충돌 발생 시**:
   - 충돌 발생 부분을 확인 (`<<<<<<<`, `=======`, `>>>>>>>` 마커 사이)
   - 팀원과 논의하여 최종 코드 결정
   - 충돌 해결 후 변경사항 커밋

### 코드 품질 관리
- **코드 스타일**: 일관된 코딩 스타일 유지 (들여쓰기, 변수 명명 규칙 등)
- **코드 리뷰**: 중요 변경사항은 최소 1명 이상의 팀원 리뷰 후 병합
- **문서화**: 주요 함수와 클래스에 설명 주석 추가
- **테스트**: 구현 완료된 기능은 실제 데이터로 테스트 후 병합
