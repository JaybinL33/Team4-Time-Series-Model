{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e2436d",
   "metadata": {},
   "source": [
    "# 시계열 분류 모델링\n",
    "\n",
    "이 노트북은 시계열 데이터에 대한 분류(Classification) 모델을 구현합니다.\n",
    "시계열 데이터를 일정 길이의 윈도우로 나누고, 각 윈도우에서 추출한 특성(통계적, 주파수, 시차 등)을 바탕으로 해당 윈도우 또는 다음 시점의 상태(범주)를 예측하는 것을 목표로 합니다.\n",
    "예를 들어, 센서 데이터 패턴을 기반으로 정상/비정상 상태를 분류하거나, 특정 시계열 패턴 발생 여부를 예측하는 문제에 적용할 수 있습니다.\n",
    "\n",
    "## 사용 가이드\n",
    "1. **데이터 설정**: `DATA_PATH`, `DATE_COL`, `TARGET_COL` 변수를 실제 데이터(타겟은 범주형 변수)에 맞게 수정합니다.\n",
    "2. **특성 엔지니어링 설정**: 분류에 사용할 특성을 결정하기 위해 시계열 윈도우 크기(`WINDOW_SIZE`), 사용할 특성 종류(`USE_XXX_FEATURES`), 시차 값(`LAG_VALUES`) 등을 조정합니다.\n",
    "3. **모델 선택**: 사용할 분류 모델(`MODELS`: RF, XGB, SVM)을 선택합니다.\n",
    "4. **실행**: 노트북을 순차적으로 실행하여 시계열 분류 모델 결과를 확인합니다.\n",
    "\n",
    "## 분석 흐름\n",
    "1. **라이브러리 임포트 및 설정**: 필요한 라이브러리를 불러오고 기본 설정을 합니다.\n",
    "2. **데이터 로드 및 탐색**: 데이터를 로드하고 기본적인 구조와 정보를 확인합니다.\n",
    "3. **타겟 변수 탐색**: 분류할 대상(타겟 변수)의 분포와 시간적 변화를 탐색하고, 필요시 레이블 인코딩을 수행합니다.\n",
    "4. **특성 변수 탐색**: 입력으로 사용할 초기 특성 변수들의 분포와 상관관계를 탐색합니다.\n",
    "5. **특성 엔지니어링**: 시계열 데이터를 윈도우 기반으로 변환하고, 각 윈도우에서 통계적 특성, 주파수 특성, 시차 특성 등을 추출하여 모델 입력용 특성 집합을 생성합니다.\n",
    "6. **데이터 분할 및 전처리**: 생성된 특성 데이터를 훈련, 검증, 테스트 세트로 분할하고 스케일링을 적용합니다. 클래스 불균형 여부도 확인합니다.\n",
    "7. **모델 훈련 및 평가**: 선택된 분류 모델들을 훈련시키고 검증 데이터로 성능을 평가합니다. (평가지표: 정확도, 정밀도, 재현율, F1 점수, 혼동 행렬)\n",
    "8. **모델 비교 및 결과 해석**: 최적 모델을 선정하고 테스트 데이터로 최종 성능을 평가합니다. (분류 보고서, 혼동 행렬, ROC 곡선 등 활용). 필요시 특성 중요도를 확인합니다.\n",
    "9. **결론 및 인사이트**: 분석 결과와 모델 성능을 요약하고 인사이트를 도출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38191c",
   "metadata": {},
   "source": [
    "## 1. 사용자 입력 파라미터 설정\n",
    "분석 데이터, 특성 생성 방식, 사용할 모델 등을 설정합니다.\n",
    "특히 시계열 분류에서는 어떤 정보를 특성으로 사용할지가 중요하므로, 특성 엔지니어링 관련 파라미터 설정이 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 필수 수정 파라미터 =====\n",
    "# 데이터 파일 경로 (CSV 형식 권장)\n",
    "DATA_PATH = \"../data/raw/your_data.csv\"\n",
    "\n",
    "# 날짜 열 이름 (데이터프레임 내 날짜/시간 정보가 있는 열)\n",
    "DATE_COL = \"date\"\n",
    "\n",
    "# 타겟 열 이름 (분류하려는 범주형 변수가 있는 열)\n",
    "TARGET_COL = \"target\"\n",
    "\n",
    "# ===== 선택적 수정 파라미터 =====\n",
    "# 특성 엔지니어링 파라미터\n",
    "WINDOW_SIZE = 24                       # 시계열 윈도우 크기\n",
    "USE_STATISTICAL_FEATURES = True        # 통계적 특성 사용 여부\n",
    "USE_FREQUENCY_FEATURES = True          # 주파수 도메인 특성 사용 여부\n",
    "USE_LAG_FEATURES = True                # 지연(lag) 특성 사용 여부\n",
    "LAG_VALUES = [1, 7, 14]                # 사용할 지연 값들\n",
    "\n",
    "# 모델 파라미터\n",
    "MODELS = [\"RF\", \"XGB\", \"SVM\"]         # 사용할 모델들 (RF: RandomForest, XGB: XGBoost, SVM: Support Vector Machine)\n",
    "TRAIN_SIZE = 0.7                       # 훈련 데이터 비율\n",
    "VALIDATION_SIZE = 0.15                 # 검증 데이터 비율 (나머지는 테스트 데이터)\n",
    "RANDOM_STATE = 42                      # 랜덤 시드\n",
    "\n",
    "# 출력 경로\n",
    "OUTPUT_DIR = '../plots'          # 시각화 결과 저장 경로\n",
    "DATA_OUTPUT_DIR = '../data/processed' # 전처리된 데이터 저장 경로\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70e628",
   "metadata": {},
   "source": [
    "## 2. 필요 라이브러리 임포트\n",
    "데이터 처리, 시각화, 특성 추출(FFT 등), 머신러닝 분류 모델 및 평가에 필요한 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f26e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.fft import fft\n",
    "\n",
    "# 머신러닝 라이브러리\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           accuracy_score, precision_score, recall_score, f1_score,\n",
    "                           roc_curve, auc, roc_auc_score)\n",
    "\n",
    "# 분류 모델\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa39e729",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드 및 탐색\n",
    "지정된 경로에서 데이터를 로드하고, 날짜 컬럼을 인덱스로 설정하며 기본적인 정보를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a63bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"데이터 로드 완료. 형태: {df.shape}\")\n",
    "\n",
    "# 날짜 열 처리\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "df.set_index(DATE_COL, inplace=True)\n",
    "print(f\"'{DATE_COL}' 열을 날짜 형식으로 변환하고 인덱스로 설정했습니다.\")\n",
    "\n",
    "# 데이터 정보 출력\n",
    "print(\"\\n데이터 기본 정보:\")\n",
    "print(df.info())\n",
    "print(\"\\n기술 통계량:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 처음 몇 행 확인\n",
    "print(\"\\n처음 5개 행:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d60f8",
   "metadata": {},
   "source": [
    "## 4. 타겟 변수 탐색\n",
    "분류 문제의 대상이 되는 타겟 변수(`TARGET_COL`)의 특성을 파악합니다.\n",
    "- **클래스 분포 확인**: 각 클래스(범주)에 속하는 데이터의 개수를 확인하여 분포를 파악하고 시각화합니다. 클래스 불균형이 심한지 확인합니다.\n",
    "- **시간에 따른 분포**: 시간에 따라 타겟 클래스가 어떻게 변화하는지 시각화합니다.\n",
    "- **레이블 인코딩**: 타겟 변수가 문자열 등 범주형일 경우, 머신러닝 모델이 처리할 수 있도록 숫자 형태로 변환(인코딩)합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수 확인\n",
    "target_values = df[TARGET_COL].value_counts()\n",
    "print(f\"\\n타겟 변수({TARGET_COL}) 분포:\")\n",
    "print(target_values)\n",
    "\n",
    "# 타겟 변수 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_values.plot(kind='bar')\n",
    "plt.title(f'타겟 변수({TARGET_COL}) 분포')\n",
    "plt.xlabel('클래스')\n",
    "plt.ylabel('빈도')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/class_타겟변수분포.png')\n",
    "plt.show()\n",
    "\n",
    "# 타겟 변수의 시계열 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "for class_value in df[TARGET_COL].unique():\n",
    "    class_data = df[df[TARGET_COL] == class_value]\n",
    "    plt.scatter(class_data.index, [class_value] * len(class_data), \n",
    "                alpha=0.6, label=f'클래스 {class_value}')\n",
    "plt.title(f'시간에 따른 {TARGET_COL} 클래스 분포')\n",
    "plt.xlabel('날짜')\n",
    "plt.ylabel(TARGET_COL)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/class_시간에따른분포.png')\n",
    "plt.show()\n",
    "\n",
    "# 타겟 변수가 범주형이 아닌 경우, 레이블 인코딩\n",
    "if df[TARGET_COL].dtype not in ['int64', 'int32', 'uint8', 'bool']:\n",
    "    print(f\"\\n타겟 변수({TARGET_COL})가 범주형이 아닌 것으로 판단됩니다. 레이블 인코딩을 수행합니다.\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[TARGET_COL] = label_encoder.fit_transform(df[TARGET_COL])\n",
    "    print(f\"레이블 인코딩 결과: {dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a9d56",
   "metadata": {},
   "source": [
    "## 5. 특성 변수 탐색\n",
    "모델 입력으로 사용될 초기 특성 변수들(타겟 변수 제외)의 분포와 상호 관계를 탐색합니다.\n",
    "- **특성 분포 시각화**: 각 특성 값의 분포를 히스토그램으로 확인합니다.\n",
    "- **상관관계 분석**: 특성 변수들 간의 선형 상관관계를 히트맵으로 시각화하여 다중공선성 등을 검토합니다.\n",
    "- **시계열 특성 시각화**: 주요 특성 변수들이 시간에 따라 어떻게 변화하는지 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5936c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 특성 선택 (타겟 변수 제외한 모든 열)\n",
    "features = [col for col in df.columns if col != TARGET_COL]\n",
    "print(f\"\\n선택된 특성({len(features)}개): {features}\")\n",
    "\n",
    "# 기본 특성 탐색\n",
    "if features:\n",
    "    # 히스토그램으로 특성 분포 시각화\n",
    "    feature_data = df[features]\n",
    "    feature_data.hist(bins=20, figsize=(14, 10))\n",
    "    plt.suptitle('특성 분포 히스토그램')\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    plt.savefig(f'{OUTPUT_DIR}/class_특성분포.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # 상관관계 분석\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation = feature_data.corr()\n",
    "    mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "    sns.heatmap(correlation, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                square=True, linewidths=.5)\n",
    "    plt.title('특성 간 상관관계')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/class_특성상관관계.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # 시계열 특성 시각화 (처음 3개 특성만)\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    for i, feature in enumerate(features[:min(3, len(features))]):\n",
    "        plt.subplot(min(3, len(features)), 1, i+1)\n",
    "        plt.plot(df.index, df[feature])\n",
    "        plt.title(f'시계열 특성: {feature}')\n",
    "        plt.xlabel('날짜')\n",
    "        plt.ylabel(feature)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/class_시계열특성.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e60317",
   "metadata": {},
   "source": [
    "## 6. 특성 엔지니어링\n",
    "시계열 데이터를 고정 길이의 윈도우로 분할하고, 각 윈도우 내에서 다양한 특성을 추출하여 분류 모델의 입력 데이터를 생성합니다.\n",
    "이 과정은 원본 시계열의 시간적 패턴 정보를 요약된 특성 벡터로 변환하는 핵심 단계입니다.\n",
    "- **통계적 특성 추출 (`extract_statistical_features`)**: 윈도우 내 데이터의 평균, 표준편차, 최소/최대값 등 통계량을 계산합니다.\n",
    "- **주파수 특성 추출 (`extract_frequency_features`)**: 윈도우 내 데이터에 FFT(고속 푸리에 변환)를 적용하여 주파수 도메인의 특성(평균, 표준편차, 최대값 등)을 추출합니다. 주기적 패턴 분석에 유용할 수 있습니다.\n",
    "- **지연 특성 추출 (`extract_lag_features`)**: 윈도우의 마지막 시점을 기준으로 과거 시점의 값(lag)을 특성으로 사용합니다.\n",
    "- **특성 집합 생성 (`create_feature_set`)**: 위 함수들을 이용하여 각 윈도우별로 모든 특성을 계산하고, 해당 윈도우 다음 시점의 타겟 값과 연결하여 최종 특성 데이터셋을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb668ad5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_statistical_features(series):\n",
    "    \"\"\"시계열 데이터에서 통계적 특성을 추출합니다.\"\"\"\n",
    "    stats_features = {}\n",
    "    \n",
    "    # 기본 통계량\n",
    "    stats_features['mean'] = series.mean()\n",
    "    stats_features['std'] = series.std()\n",
    "    stats_features['min'] = series.min()\n",
    "    stats_features['max'] = series.max()\n",
    "    stats_features['median'] = series.median()\n",
    "    \n",
    "    # 백분위수\n",
    "    stats_features['q25'] = series.quantile(0.25)\n",
    "    stats_features['q75'] = series.quantile(0.75)\n",
    "    stats_features['iqr'] = stats_features['q75'] - stats_features['q25']\n",
    "    \n",
    "    # 왜도와 첨도\n",
    "    stats_features['skew'] = series.skew()\n",
    "    stats_features['kurtosis'] = series.kurtosis()\n",
    "    \n",
    "    return stats_features\n",
    "\n",
    "def extract_frequency_features(series):\n",
    "    \"\"\"시계열 데이터에서 주파수 도메인 특성을 추출합니다.\"\"\"\n",
    "    freq_features = {}\n",
    "    \n",
    "    # FFT 변환\n",
    "    fft_values = fft(series.values)\n",
    "    fft_abs = np.abs(fft_values)\n",
    "    \n",
    "    # 주요 주파수 특성\n",
    "    freq_features['fft_mean'] = np.mean(fft_abs)\n",
    "    freq_features['fft_std'] = np.std(fft_abs)\n",
    "    freq_features['fft_max'] = np.max(fft_abs)\n",
    "    \n",
    "    # 주파수 스펙트럼의 상위 5개 값\n",
    "    top_indices = np.argsort(fft_abs)[-5:]\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        freq_features[f'fft_top{i+1}'] = fft_abs[idx]\n",
    "    \n",
    "    return freq_features\n",
    "\n",
    "def extract_lag_features(series, lags):\n",
    "    \"\"\"시계열 데이터에서 지연(lag) 특성을 추출합니다.\"\"\"\n",
    "    lag_features = {}\n",
    "    \n",
    "    for lag in lags:\n",
    "        lag_features[f'lag_{lag}'] = series.shift(lag).iloc[-1]\n",
    "    \n",
    "    return lag_features\n",
    "\n",
    "# 윈도우 기반 특성 추출\n",
    "def create_feature_set(df, features, window_size, target_col, \n",
    "                       use_statistical=True, use_frequency=True, use_lag=True, lag_values=None):\n",
    "    \"\"\"윈도우 기반의 특성 집합을 생성합니다.\"\"\"\n",
    "    feature_sets = []\n",
    "    \n",
    "    # 날짜 범위의 끝에서부터 특성 추출 시작\n",
    "    for end_idx in range(window_size, len(df) + 1):\n",
    "        window_data = df.iloc[end_idx - window_size:end_idx]\n",
    "        features_dict = {}\n",
    "        \n",
    "        # 각 특성별로 윈도우 특성 추출\n",
    "        for feature in features:\n",
    "            series = window_data[feature]\n",
    "            feature_prefix = f\"{feature}_\"\n",
    "            \n",
    "            # 통계적 특성\n",
    "            if use_statistical:\n",
    "                stat_features = extract_statistical_features(series)\n",
    "                for key, value in stat_features.items():\n",
    "                    features_dict[feature_prefix + key] = value\n",
    "            \n",
    "            # 주파수 특성\n",
    "            if use_frequency:\n",
    "                freq_features = extract_frequency_features(series)\n",
    "                for key, value in freq_features.items():\n",
    "                    features_dict[feature_prefix + key] = value\n",
    "            \n",
    "            # 지연 특성\n",
    "            if use_lag and lag_values:\n",
    "                lag_features = extract_lag_features(df[feature].iloc[:end_idx], lag_values)\n",
    "                for key, value in lag_features.items():\n",
    "                    features_dict[feature_prefix + key] = value\n",
    "        \n",
    "        # 타겟 값\n",
    "        if end_idx < len(df):\n",
    "            features_dict['target'] = df[target_col].iloc[end_idx]\n",
    "        \n",
    "        feature_sets.append(features_dict)\n",
    "    \n",
    "    # 마지막 윈도우는 예측용이므로 타겟이 없음\n",
    "    feature_sets = feature_sets[:-1]\n",
    "    \n",
    "    return pd.DataFrame(feature_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd8c6a6",
   "metadata": {},
   "source": [
    "## 7. 특성 집합 생성\n",
    "정의된 함수를 사용하여 실제 특성 엔지니어링을 수행하고, 생성된 특성 데이터셋을 확인합니다.\n",
    "특성 생성 과정에서 발생할 수 있는 결측치는 평균값으로 대체합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e172c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"윈도우 기반 특성 집합을 생성합니다...\")\n",
    "features_df = create_feature_set(\n",
    "    df, features, WINDOW_SIZE, TARGET_COL,\n",
    "    use_statistical=USE_STATISTICAL_FEATURES,\n",
    "    use_frequency=USE_FREQUENCY_FEATURES,\n",
    "    use_lag=USE_LAG_FEATURES,\n",
    "    lag_values=LAG_VALUES\n",
    ")\n",
    "\n",
    "print(f\"생성된 특성 집합 형태: {features_df.shape}\")\n",
    "print(\"\\n생성된 특성 목록 (처음 10개):\")\n",
    "feature_cols = [col for col in features_df.columns if col != 'target']\n",
    "for col in feature_cols[:10]:\n",
    "    print(f\"- {col}\")\n",
    "if len(feature_cols) > 10:\n",
    "    print(f\"... 외 {len(feature_cols) - 10}개\")\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"\\n특성 집합 처음 5개 행:\")\n",
    "print(features_df.head())\n",
    "\n",
    "# 결측치 처리\n",
    "missing_values = features_df.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"\\n결측치가 있는 특성 수:\", (missing_values > 0).sum())\n",
    "    \n",
    "    # 결측치 처리 (평균으로 대체)\n",
    "    features_df = features_df.fillna(features_df.mean())\n",
    "    print(\"결측치를 평균값으로 대체했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9401e",
   "metadata": {},
   "source": [
    "## 8. 데이터 분할 및 전처리\n",
    "생성된 특성 데이터셋을 모델 학습과 평가를 위해 훈련, 검증, 테스트 세트로 분할합니다.\n",
    "시계열 데이터의 특성을 고려하여 시간 순서를 유지하며 분할하는 대신, 여기서는 일반적인 분류 문제처럼 랜덤 분할(`train_test_split`)을 사용합니다. (필요시 시간 순서 분할 방식으로 변경 가능)\n",
    "특성 스케일링(`StandardScaler`)을 적용하여 모델 학습 성능을 높입니다.\n",
    "훈련 데이터의 클래스 분포를 확인하여 불균형 문제를 인지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92559825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성과 타겟 분리\n",
    "X = features_df.drop('target', axis=1)\n",
    "y = features_df['target']\n",
    "\n",
    "# 데이터 분할 (훈련, 검증, 테스트)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=(1 - TRAIN_SIZE - VALIDATION_SIZE), random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=VALIDATION_SIZE/(TRAIN_SIZE + VALIDATION_SIZE), \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"데이터 분할 완료:\")\n",
    "print(f\"- 훈련 데이터: {X_train.shape}\")\n",
    "print(f\"- 검증 데이터: {X_val.shape}\")\n",
    "print(f\"- 테스트 데이터: {X_test.shape}\")\n",
    "\n",
    "# 특성 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n특성 스케일링 완료\")\n",
    "\n",
    "# 레이블 분포 확인\n",
    "train_class_counts = pd.Series(y_train).value_counts()\n",
    "print(\"\\n훈련 데이터 클래스 분포:\")\n",
    "print(train_class_counts)\n",
    "\n",
    "# 불균형 확인\n",
    "if len(train_class_counts) > 1:  # 클래스가 2개 이상인 경우\n",
    "    max_class = train_class_counts.max()\n",
    "    min_class = train_class_counts.min()\n",
    "    imbalance_ratio = max_class / min_class\n",
    "    \n",
    "    print(f\"\\n클래스 불균형 비율: {imbalance_ratio:.2f}\")\n",
    "    if imbalance_ratio > 3:\n",
    "        print(\"경고: 클래스 불균형이 크게 발생했습니다. 균형 조정 기법 사용을 고려하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336bc5f",
   "metadata": {},
   "source": [
    "## 9. 모델 훈련 및 평가\n",
    "선택된 분류 모델(Random Forest, XGBoost, SVM)들을 훈련 데이터로 학습시키고, 검증 데이터로 성능을 평가하여 최적 모델을 찾습니다.\n",
    "- **모델 정의**: 각 분류 모델 객체를 생성합니다.\n",
    "- **훈련 및 평가**: 각 모델을 훈련(`fit`)하고 검증 세트로 예측(`predict`)하여 성능 지표(정확도, 정밀도, 재현율, F1 점수)를 계산합니다. 혼동 행렬을 시각화하여 분류 성능을 상세히 분석합니다.\n",
    "- **최적 모델 선정**: 검증 세트에서의 F1 점수를 기준으로 가장 성능이 좋은 모델을 선택합니다.\n",
    "- **최종 평가**: 선택된 최적 모델을 사용하여 테스트 세트에 대한 최종 성능을 평가하고, 분류 보고서, 혼동 행렬, ROC 곡선(이진 분류 시) 등을 통해 결과를 제시합니다. Tree 기반 모델의 경우 특성 중요도도 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a364bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 사전 정의\n",
    "models = {}\n",
    "\n",
    "if \"RF\" in MODELS:\n",
    "    models[\"RandomForest\"] = RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        max_depth=10, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "if \"XGB\" in MODELS:\n",
    "    models[\"XGBoost\"] = XGBClassifier(\n",
    "        n_estimators=100, \n",
    "        max_depth=5, \n",
    "        learning_rate=0.1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "if \"SVM\" in MODELS:\n",
    "    models[\"SVM\"] = SVC(\n",
    "        kernel='rbf', \n",
    "        probability=True,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "# 모델 훈련 및 평가\n",
    "model_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} 모델 훈련 중...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 예측\n",
    "    y_val_pred = model.predict(X_val_scaled)\n",
    "    \n",
    "    # 성능 평가\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "    recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "    f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    print(f\"{name} 검증 성능:\")\n",
    "    print(f\"- 정확도: {accuracy:.4f}\")\n",
    "    print(f\"- 정밀도: {precision:.4f}\")\n",
    "    print(f\"- 재현율: {recall:.4f}\")\n",
    "    print(f\"- F1 점수: {f1:.4f}\")\n",
    "    \n",
    "    # 혼동 행렬\n",
    "    cm = confusion_matrix(y_val, y_val_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{name} 혼동 행렬')\n",
    "    plt.xlabel('예측 클래스')\n",
    "    plt.ylabel('실제 클래스')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/class_{name}_혼동행렬.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # 결과 저장\n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# 최고 성능 모델 선택\n",
    "if model_results:\n",
    "    best_model_name = max(model_results, key=lambda x: model_results[x]['f1'])\n",
    "    best_model = model_results[best_model_name]['model']\n",
    "    \n",
    "    print(f\"\\n최고 성능 모델: {best_model_name}\")\n",
    "    print(f\"검증 F1 점수: {model_results[best_model_name]['f1']:.4f}\")\n",
    "    \n",
    "    # 최고 모델로 테스트 데이터 평가\n",
    "    y_test_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # 테스트 성능 평가\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n{best_model_name} 테스트 성능:\")\n",
    "    print(f\"- 정확도: {test_accuracy:.4f}\")\n",
    "    print(f\"- 정밀도: {test_precision:.4f}\")\n",
    "    print(f\"- 재현율: {test_recall:.4f}\")\n",
    "    print(f\"- F1 점수: {test_f1:.4f}\")\n",
    "    \n",
    "    # 분류 보고서\n",
    "    print(\"\\n분류 보고서:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # 최종 혼동 행렬\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{best_model_name} 테스트 혼동 행렬')\n",
    "    plt.xlabel('예측 클래스')\n",
    "    plt.ylabel('실제 클래스')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/class_최종_혼동행렬.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # 이진 분류인 경우 ROC 곡선\n",
    "    if len(np.unique(y)) == 2:\n",
    "        y_test_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC 곡선 (AUC = {roc_auc:.4f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC 곡선')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/class_ROC곡선.png')\n",
    "        plt.show()\n",
    "        \n",
    "    # 특성 중요도 (RandomForest와 XGBoost의 경우)\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='importance', y='feature', data=feature_importance.head(20))\n",
    "        plt.title(f'{best_model_name} 특성 중요도 (상위 20개)')\n",
    "        plt.xlabel('중요도')\n",
    "        plt.ylabel('특성')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/class_특성중요도.png')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n상위 10개 중요 특성:\")\n",
    "        print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de1e00",
   "metadata": {},
   "source": [
    "## 10. 결론 및 인사이트\n",
    "전체 시계열 분류 모델링 과정과 최종 결과를 요약합니다.\n",
    "데이터 정보, 사용된 특성 수, 각 모델의 검증 성능, 최적 모델의 최종 테스트 성능 등을 제시하고 분석에 대한 결론과 인사이트를 정리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08449c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"시계열 분류 모델링 요약\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\n1. 데이터 정보:\")\n",
    "print(f\"   - 데이터 기간: {df.index.min()} ~ {df.index.max()}\")\n",
    "print(f\"   - 데이터 포인트 수: {len(df)}\")\n",
    "print(f\"   - 특성 수: {len(features)}\")\n",
    "print(f\"   - 추출된 특성 수: {X.shape[1]}\")\n",
    "\n",
    "print(f\"\\n2. 모델 성능:\")\n",
    "for model_name, results in model_results.items():\n",
    "    print(f\"   - {model_name}: 검증 F1 = {results['f1']:.4f}, 정확도 = {results['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. 최고 성능 모델: {best_model_name}\")\n",
    "print(f\"   - 테스트 F1: {test_f1:.4f}\")\n",
    "print(f\"   - 테스트 정확도: {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n시계열 분류 모델링이 완료되었습니다!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
