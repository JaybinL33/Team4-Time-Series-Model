{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f37ecc",
   "metadata": {},
   "source": [
    "# 시계열 머신러닝 모델링\n",
    "\n",
    "이 노트북은 시계열 데이터에 대해 특성 엔지니어링(Feature Engineering)을 수행하고, 이를 입력으로 사용하여 머신러닝 모델(Linear Regression, RandomForest, XGBoost)을 학습시켜 미래 값을 예측하는 과정을 보여줍니다.\n",
    "시계열 자체의 순서나 시간적 의존성을 직접 모델링하는 ARIMA나 LSTM과 달리, 이 접근 방식은 과거 시점의 값(lag), 이동 통계량, 날짜 정보 등을 독립적인 특성으로 만들어 일반적인 지도 학습(Supervised Learning) 회귀 문제처럼 다룹니다.\n",
    "\n",
    "## 사용 가이드\n",
    "1. **데이터 경로 설정**: `DATA_PATH` 변수를 실제 데이터 파일 경로로 변경합니다.\n",
    "2. **날짜/타겟 열 이름**: `DATE_COL`과 `TARGET_COL` 변수를 데이터에 맞게 변경합니다.\n",
    "3. **특성 엔지니어링 파라미터**: 시차(`LAG_PERIODS`), 이동 윈도우(`ROLLING_WINDOWS`), 날짜 특성 사용 여부(`USE_XXX_FEATURES`) 등을 필요에 따라 조정합니다.\n",
    "4. **모델 선택**: 사용할 머신러닝 모델(`MODELS`)을 리스트에 지정합니다.\n",
    "5. **실행**: 전체 노트북 셀을 순차적으로 실행하여 모델 결과를 확인합니다.\n",
    "\n",
    "## 분석 흐름\n",
    "1. **라이브러리 임포트 및 설정**: 필요한 라이브러리를 불러오고 기본 설정을 합니다.\n",
    "2. **데이터 로드 및 탐색**: 데이터를 불러와 기본적인 정보와 구조를 파악합니다.\n",
    "3. **시계열 데이터 시각화**: 원본 데이터의 추세, 패턴, 분포 등을 시각적으로 확인합니다.\n",
    "4. **시계열 분해 및 정상성 검정**: 데이터의 추세, 계절성, 잔차 성분을 분해하고 정상성 여부를 검토합니다. (머신러닝 모델은 ARIMA와 달리 정상성이 필수 조건은 아니지만, 데이터 이해를 위해 수행)\n",
    "5. **특성 엔지니어링**: 시계열 데이터를 머신러닝 모델의 입력으로 사용하기 위해 다양한 특성(날짜, 시차, 이동 통계량 등)을 생성합니다.\n",
    "6. **데이터 분할 및 전처리**: 생성된 특성 데이터를 훈련, 검증, 테스트 세트로 분할하고, 스케일링을 적용합니다.\n",
    "7. **모델 훈련 및 평가**: 선택된 머신러닝 모델들을 훈련시키고 성능을 평가합니다.\n",
    "8. **모델 비교**: 각 모델의 성능 지표를 비교하여 최적 모델을 선정합니다. (필요시 특성 중요도 확인)\n",
    "9. **미래 예측**: 선택된 최적 모델을 사용하여 미래 기간의 값을 예측합니다.\n",
    "10. **결론 및 인사이트**: 분석 결과와 모델 성능을 요약하고 인사이트를 도출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ac8354",
   "metadata": {},
   "source": [
    "## 1. 사용자 입력 파라미터 설정\n",
    "분석 대상 데이터, 특성 생성 방식, 사용할 모델 등 주요 파라미터를 설정합니다.\n",
    "사용자의 데이터와 분석 목적에 맞게 이 섹션의 값들을 수정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58795a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 필수 수정 파라미터 =====\n",
    "# 데이터 파일 경로 (CSV 형식 권장)\n",
    "DATA_PATH = \"../data/raw/your_data.csv\"\n",
    "\n",
    "# 날짜 열 이름 (데이터프레임 내 날짜/시간 정보가 있는 열)\n",
    "DATE_COL = \"date\"\n",
    "\n",
    "# 타겟 열 이름 (예측하려는 변수가 있는 열)\n",
    "TARGET_COL = \"value\"\n",
    "\n",
    "# ===== 선택적 수정 파라미터 =====\n",
    "# 훈련/검증/테스트 분할 비율\n",
    "TRAIN_SIZE = 0.7                         # 훈련 데이터 비율\n",
    "VALIDATION_SIZE = 0.15                   # 검증 데이터 비율 (나머지는 테스트 데이터)\n",
    "\n",
    "# 특성 엔지니어링 파라미터\n",
    "USE_LAG_FEATURES = True                  # 시차(lag) 특성 사용 여부\n",
    "LAG_PERIODS = [1, 7, 14, 30]             # 사용할 시차 기간\n",
    "USE_ROLLING_FEATURES = True              # 이동 평균/표준편차 특성 사용 여부\n",
    "ROLLING_WINDOWS = [7, 14, 30]            # 이동 윈도우 크기\n",
    "USE_DATE_FEATURES = True                 # 날짜 기반 특성 사용 여부\n",
    "\n",
    "# 사용할 머신러닝 모델\n",
    "MODELS = [\"LR\", \"RF\", \"XGB\"]            # LR: LinearRegression, RF: RandomForest, XGB: XGBoost\n",
    "\n",
    "# 예측 기간 (일 단위)\n",
    "FORECAST_HORIZON = 30\n",
    "\n",
    "# 랜덤 시드\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 출력 경로\n",
    "OUTPUT_DIR = '../plots'\n",
    "DATA_OUTPUT_DIR = '../data/processed'\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2fe8ab",
   "metadata": {},
   "source": [
    "## 2. 필요 라이브러리 임포트\n",
    "데이터 처리(pandas, numpy), 시각화(matplotlib, seaborn), 시계열 분석(statsmodels), 머신러닝(sklearn, xgboost) 등에 필요한 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# 시계열 라이브러리\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# 머신러닝 라이브러리\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# 랜덤 시드 설정 (모델 재현성을 위해)\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830b069",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드 및 탐색\n",
    "지정된 경로의 데이터를 불러와 Pandas 데이터프레임으로 변환하고, 기본적인 정보(행/열 개수, 컬럼 타입, 통계 요약)를 확인합니다.\n",
    "날짜 컬럼은 datetime 형식으로 변환하여 시계열 분석 준비를 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"데이터 로드 완료. 형태: {df.shape}\")\n",
    "\n",
    "# 날짜 열 처리\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "df.set_index(DATE_COL, inplace=True)\n",
    "print(f\"'{DATE_COL}' 열을 날짜 형식으로 변환하고 인덱스로 설정했습니다.\")\n",
    "\n",
    "# 데이터 정보 확인\n",
    "print(\"\\n데이터 기본 정보:\")\n",
    "print(df.info())\n",
    "print(\"\\n기술 통계량:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 처음 몇 행 확인\n",
    "print(\"\\n처음 5개 행:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e8ad60",
   "metadata": {},
   "source": [
    "## 4. 시계열 데이터 시각화\n",
    "타겟 변수의 시계열 변화와 값의 분포를 시각적으로 탐색합니다.\n",
    "- **선 그래프**: 시간 흐름에 따른 타겟 변수의 전반적인 추세와 패턴을 확인합니다.\n",
    "- **분포 플롯 (히스토그램, 박스플롯)**: 타겟 변수 값의 분포 형태, 중심 경향성, 이상치 존재 여부 등을 파악합니다.\n",
    "결측치가 있다면 선형 보간법으로 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d12522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수 시계열 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df.index, df[TARGET_COL], marker='.', linestyle='-', alpha=0.8)\n",
    "plt.title(f'{TARGET_COL} 시계열 데이터')\n",
    "plt.xlabel('날짜')\n",
    "plt.ylabel(TARGET_COL)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ml_시계열_원본.png')\n",
    "plt.show()\n",
    "\n",
    "# 타겟 변수 분포\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[TARGET_COL], kde=True)\n",
    "plt.title(f'{TARGET_COL} 분포')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df[TARGET_COL])\n",
    "plt.title(f'{TARGET_COL} 박스플롯')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ml_타겟_분포.png')\n",
    "plt.show()\n",
    "\n",
    "# 결측치 확인 및 처리\n",
    "missing_values = df[TARGET_COL].isnull().sum()\n",
    "print(f\"\\n{TARGET_COL} 결측치 개수: {missing_values}\")\n",
    "\n",
    "if missing_values > 0:\n",
    "    df[TARGET_COL] = df[TARGET_COL].interpolate(method='linear')\n",
    "    print(f\"{TARGET_COL} 결측치를 선형 보간하여 처리했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7908c3e",
   "metadata": {},
   "source": [
    "## 5. 시계열 분해 및 정상성 검정\n",
    "시계열 데이터의 구조적 특징을 더 깊이 이해하기 위해 구성 요소를 분해하고 정상성을 검정합니다.\n",
    "- **시계열 분해**: 데이터를 추세, 계절성, 잔차로 분해하여 각 성분의 영향을 시각적으로 확인합니다. (여기서는 가법 모델 사용)\n",
    "- **정상성 검정 (ADF)**: 시계열의 통계적 특성이 시간에 따라 변하지 않는지(정상성) 검정합니다. 머신러닝 모델은 정상성이 필수 조건은 아니지만, 데이터 특성 파악에 도움이 됩니다.\n",
    "- **ACF/PACF 플롯**: 시계열 내 자기상관 구조를 시각적으로 확인합니다. ARIMA 모델처럼 직접적으로 파라미터 결정에 사용되지는 않지만, 데이터의 의존성 패턴을 이해하는 데 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe9d5a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 시계열 분해 (가법 모델 사용)\n",
    "# 참고: seasonal_decompose는 데이터 길이가 period의 2배 이상이어야 정상 작동합니다.\n",
    "#      데이터가 짧거나 주기가 불분명하면 오류가 발생할 수 있습니다.\n",
    "decomposition = seasonal_decompose(df[TARGET_COL], model='additive', period=7)\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(decomposition.observed)\n",
    "plt.title('원본 시계열')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(decomposition.trend)\n",
    "plt.title('추세 성분')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(decomposition.seasonal)\n",
    "plt.title('계절성 성분')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(decomposition.resid)\n",
    "plt.title('잔차')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ml_시계열_분해.png')\n",
    "plt.show()\n",
    "\n",
    "# 정상성 검정 (ADF 테스트)\n",
    "adf_result = adfuller(df[TARGET_COL].dropna())\n",
    "print(\"\\nADF 정상성 검정 결과:\")\n",
    "print(f\"ADF 통계량: {adf_result[0]:.4f}\")\n",
    "print(f\"p-값: {adf_result[1]:.4f}\")\n",
    "\n",
    "# 정상성 판단\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"결론: 시계열이 정상적일 가능성이 높습니다 (p < 0.05).\")\n",
    "else:\n",
    "    print(\"결론: 시계열이 비정상적일 가능성이 높습니다 (p >= 0.05).\")\n",
    "\n",
    "# 자기상관 및 부분 자기상관 함수\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_acf(df[TARGET_COL].dropna(), lags=40, alpha=0.05, ax=plt.gca())\n",
    "plt.title('자기상관함수(ACF)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_pacf(df[TARGET_COL].dropna(), lags=40, alpha=0.05, method='ywm', ax=plt.gca())\n",
    "plt.title('부분 자기상관함수(PACF)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ml_ACF_PACF.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a574ea4",
   "metadata": {},
   "source": [
    "## 6. 특성 엔지니어링\n",
    "시계열 데이터를 머신러닝 모델이 학습할 수 있는 형태의 특성(feature)으로 변환하는 과정입니다.\n",
    "- **날짜 특성**: 연, 월, 요일, 분기 등 날짜/시간 정보에서 파생된 특성. 주기성이나 특정 시점의 효과를 모델링하는 데 사용됩니다.\n",
    "- **시차(Lag) 특성**: 과거 시점의 타겟 변수 값. 자기회귀(Autoregressive) 효과를 반영합니다. (예: 어제의 값이 오늘의 값에 영향을 미치는 경우)\n",
    "- **이동(Rolling) 특성**: 과거 일정 기간(윈도우) 동안의 타겟 변수 통계량(평균, 표준편차 등). 최근 데이터의 추세나 변동성을 요약하여 특성으로 사용합니다.\n",
    "생성된 특성들과 타겟 변수 간의 상관관계를 확인하여 모델링에 유용할 특성을 탐색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860a38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features(df):\n",
    "    \"\"\"날짜 인덱스로부터 특성을 생성합니다.\"\"\"\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # 날짜 성분 추출\n",
    "    df_features['dayofweek'] = df.index.dayofweek\n",
    "    df_features['quarter'] = df.index.quarter\n",
    "    df_features['month'] = df.index.month\n",
    "    df_features['year'] = df.index.year\n",
    "    df_features['dayofyear'] = df.index.dayofyear\n",
    "    df_features['dayofmonth'] = df.index.day\n",
    "    df_features['weekofyear'] = df.index.isocalendar().week\n",
    "    \n",
    "    # 주말/평일 특성\n",
    "    df_features['is_weekend'] = df_features['dayofweek'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # 계절 특성\n",
    "    df_features['season'] = (df_features['month'] % 12 + 3) // 3\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "def create_lag_features(df, target_col, lag_periods):\n",
    "    \"\"\"시차(lag) 특성을 생성합니다.\"\"\"\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # 시차 특성 생성\n",
    "    for lag in lag_periods:\n",
    "        df_features[f'lag_{lag}'] = df_features[target_col].shift(lag)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "def create_rolling_features(df, target_col, windows):\n",
    "    \"\"\"이동 윈도우(rolling) 특성을 생성합니다.\"\"\"\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # 이동 평균 및 표준편차\n",
    "    for window in windows:\n",
    "        df_features[f'rolling_mean_{window}'] = df_features[target_col].rolling(window=window).mean()\n",
    "        df_features[f'rolling_std_{window}'] = df_features[target_col].rolling(window=window).std()\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# 특성 데이터프레임 생성\n",
    "features_df = df.copy()\n",
    "\n",
    "# 날짜 특성 생성\n",
    "if USE_DATE_FEATURES:\n",
    "    features_df = create_date_features(features_df)\n",
    "    print(\"날짜 기반 특성이 생성되었습니다.\")\n",
    "\n",
    "# 시차 특성 생성\n",
    "if USE_LAG_FEATURES:\n",
    "    features_df = create_lag_features(features_df, TARGET_COL, LAG_PERIODS)\n",
    "    print(\"시차(lag) 특성이 생성되었습니다.\")\n",
    "\n",
    "# 이동 윈도우 특성 생성\n",
    "if USE_ROLLING_FEATURES:\n",
    "    features_df = create_rolling_features(features_df, TARGET_COL, ROLLING_WINDOWS)\n",
    "    print(\"이동 윈도우(rolling) 특성이 생성되었습니다.\")\n",
    "\n",
    "# 특성 및 타겟 변수 분리\n",
    "X = features_df.drop(TARGET_COL, axis=1)\n",
    "y = features_df[TARGET_COL]\n",
    "\n",
    "# 결측치 처리 (특성 생성으로 인한 초기 결측치 제거)\n",
    "max_lag = 0\n",
    "if USE_LAG_FEATURES:\n",
    "    max_lag = max(max_lag, max(LAG_PERIODS))\n",
    "if USE_ROLLING_FEATURES:\n",
    "    max_lag = max(max_lag, max(ROLLING_WINDOWS))\n",
    "\n",
    "if max_lag > 0:\n",
    "    X = X.iloc[max_lag:]\n",
    "    y = y.iloc[max_lag:]\n",
    "    print(f\"특성 생성으로 인한 결측치를 처리했습니다. 처리 후 데이터 크기: {X.shape}\")\n",
    "\n",
    "# 특성 정보 출력\n",
    "print(\"\\n생성된 특성:\")\n",
    "for col in X.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# 상관관계 시각화\n",
    "plt.figure(figsize=(14, 12))\n",
    "# 특성이 너무 많으면 상위 20개만 선택\n",
    "if X.shape[1] > 20:\n",
    "    # 타겟과의 상관관계 기준으로 상위 특성 선택\n",
    "    correlations = X.apply(lambda x: x.corr(y) if x.dtype.kind in 'bifc' else 0)\n",
    "    top_features = correlations.abs().nlargest(20).index\n",
    "    correlation_matrix = pd.concat([X[top_features], y], axis=1).corr()\n",
    "else:\n",
    "    correlation_matrix = pd.concat([X, y], axis=1).corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(\n",
    "    correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "    cmap='coolwarm', vmin=-1, vmax=1\n",
    ")\n",
    "plt.title('특성 간 상관관계')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ml_특성_상관관계.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f343463",
   "metadata": {},
   "source": [
    "## 7. 데이터 분할 및 전처리\n",
    "생성된 특성 데이터를 모델 학습 및 평가를 위해 훈련, 검증, 테스트 세트로 분할합니다. 시계열 데이터의 순서를 유지하며 분할하는 것이 중요합니다.\n",
    "또한, 머신러닝 모델의 성능 향상과 안정적인 학습을 위해 특성 스케일링(여기서는 StandardScaler)을 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e67f23",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 훈련/검증/테스트 데이터 분할 (시간 순서 유지)\n",
    "train_val_split_idx = int(len(X) * TRAIN_SIZE)\n",
    "val_test_split_idx = int(len(X) * (TRAIN_SIZE + VALIDATION_SIZE))\n",
    "\n",
    "X_train = X.iloc[:train_val_split_idx]\n",
    "y_train = y.iloc[:train_val_split_idx]\n",
    "\n",
    "X_val = X.iloc[train_val_split_idx:val_test_split_idx]\n",
    "y_val = y.iloc[train_val_split_idx:val_test_split_idx]\n",
    "\n",
    "X_test = X.iloc[val_test_split_idx:]\n",
    "y_test = y.iloc[val_test_split_idx:]\n",
    "\n",
    "print(f\"데이터 분할 완료:\")\n",
    "print(f\"- 훈련 데이터: {X_train.shape}\")\n",
    "print(f\"- 검증 데이터: {X_val.shape}\")\n",
    "print(f\"- 테스트 데이터: {X_test.shape}\")\n",
    "\n",
    "# 데이터 전처리 - 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val) # 검증 데이터는 transform만 적용\n",
    "X_test_scaled = scaler.transform(X_test) # 테스트 데이터는 transform만 적용\n",
    "\n",
    "print(f\"\\n전처리 후 훈련 데이터: {X_train_scaled.shape}\")\n",
    "print(f\"전처리 후 검증 데이터: {X_val_scaled.shape}\")\n",
    "print(f\"전처리 후 테스트 데이터: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7930c3fc",
   "metadata": {},
   "source": [
    "## 8. 모델 훈련 및 평가\n",
    "선택된 머신러닝 모델(Linear Regression, RandomForest, XGBoost)들을 준비된 훈련 데이터로 학습시키고, 테스트 데이터로 예측 성능을 평가합니다.\n",
    "- **모델 정의**: 각 모델 객체를 생성합니다. (하이퍼파라미터는 기본값 또는 간단한 설정 사용)\n",
    "- **훈련**: `fit()` 메서드를 사용하여 모델을 학습시킵니다.\n",
    "- **예측**: 학습된 모델로 훈련 및 테스트 데이터에 대한 예측을 수행합니다 (`predict()` 사용).\n",
    "- **평가**: 예측값과 실제값을 비교하여 성능 지표(RMSE, MAE, R²)를 계산합니다. 시각화를 통해 예측 결과를 직관적으로 확인합니다.\n",
    "함수(`train_and_evaluate_model`)를 사용하여 반복 작업을 효율화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9666aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"모델을 훈련하고 평가합니다.\"\"\"\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 예측\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 평가 지표 계산\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"\\n===== {model_name} 모델 평가 =====\")\n",
    "    print(f\"훈련 RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"테스트 RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"훈련 MAE: {train_mae:.4f}\")\n",
    "    print(f\"테스트 MAE: {test_mae:.4f}\")\n",
    "    print(f\"훈련 R²: {train_r2:.4f}\")\n",
    "    print(f\"테스트 R²: {test_r2:.4f}\")\n",
    "    \n",
    "    # 결과 시각화\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # 시계열 예측 시각화\n",
    "    plt.plot(y_train.index, y_train.values, 'b-', label='훈련 실제값')\n",
    "    plt.plot(y_train.index, y_train_pred, 'r--', label='훈련 예측값')\n",
    "    plt.plot(y_test.index, y_test.values, 'g-', label='테스트 실제값')\n",
    "    plt.plot(y_test.index, y_test_pred, 'm--', label='테스트 예측값')\n",
    "    \n",
    "    plt.title(f'{model_name} 시계열 예측')\n",
    "    plt.xlabel('날짜')\n",
    "    plt.ylabel(TARGET_COL)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/ml_{model_name}_시계열예측.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'y_test_pred': y_test_pred\n",
    "    }\n",
    "\n",
    "# 모델 훈련 및 평가\n",
    "model_results = {}\n",
    "\n",
    "# 선형 회귀 모델\n",
    "if \"LR\" in MODELS:\n",
    "    lr_model = LinearRegression()\n",
    "    model_results['LinearRegression'] = train_and_evaluate_model(\n",
    "        lr_model, X_train_scaled, y_train, X_test_scaled, y_test, 'LinearRegression'\n",
    "    )\n",
    "\n",
    "# 랜덤 포레스트 모델\n",
    "if \"RF\" in MODELS:\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=10, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    model_results['RandomForest'] = train_and_evaluate_model(\n",
    "        rf_model, X_train_scaled, y_train, X_test_scaled, y_test, 'RandomForest'\n",
    "    )\n",
    "\n",
    "# XGBoost 모델\n",
    "if \"XGB\" in MODELS:\n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=5, \n",
    "        learning_rate=0.1, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    model_results['XGBoost'] = train_and_evaluate_model(\n",
    "        xgb_model, X_train_scaled, y_train, X_test_scaled, y_test, 'XGBoost'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4c52f",
   "metadata": {},
   "source": [
    "## 9. 모델 비교\n",
    "여러 모델의 평가 결과를 비교하여 어떤 모델이 해당 데이터와 문제에 가장 적합한지 판단합니다.\n",
    "- **성능 비교**: 테스트 세트에 대한 평가지표(RMSE, MAE, R²)를 표와 그래프로 비교합니다.\n",
    "- **최적 모델 선정**: 가장 우수한 성능을 보인 모델을 선택합니다. (여기서는 R² 기준)\n",
    "- **특성 중요도 (Tree 기반 모델)**: RandomForest나 XGBoost와 같이 특성 중요도를 제공하는 모델의 경우, 어떤 특성이 예측에 중요하게 사용되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811113ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 비교\n",
    "if model_results:\n",
    "    model_comparison = pd.DataFrame({\n",
    "        'Model': list(model_results.keys()),\n",
    "        'Train RMSE': [results['train_rmse'] for results in model_results.values()],\n",
    "        'Test RMSE': [results['test_rmse'] for results in model_results.values()],\n",
    "        'Train MAE': [results['train_mae'] for results in model_results.values()],\n",
    "        'Test MAE': [results['test_mae'] for results in model_results.values()],\n",
    "        'Train R²': [results['train_r2'] for results in model_results.values()],\n",
    "        'Test R²': [results['test_r2'] for results in model_results.values()]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n===== 모델 성능 비교 =====\")\n",
    "    print(model_comparison.set_index('Model'))\n",
    "    \n",
    "    # 모델 성능 비교 시각화\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # RMSE 비교\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(model_comparison['Model'], model_comparison['Test RMSE'])\n",
    "    plt.title('테스트 RMSE 비교')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE 비교\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.bar(model_comparison['Model'], model_comparison['Test MAE'])\n",
    "    plt.title('테스트 MAE 비교')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # R² 비교\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.bar(model_comparison['Model'], model_comparison['Test R²'])\n",
    "    plt.title('테스트 R² 비교')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 훈련/테스트 RMSE 비교\n",
    "    plt.subplot(2, 2, 4)\n",
    "    width = 0.35\n",
    "    x = np.arange(len(model_comparison['Model']))\n",
    "    plt.bar(x - width/2, model_comparison['Train RMSE'], width, label='훈련 RMSE')\n",
    "    plt.bar(x + width/2, model_comparison['Test RMSE'], width, label='테스트 RMSE')\n",
    "    plt.title('훈련/테스트 RMSE 비교')\n",
    "    plt.xticks(x, model_comparison['Model'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/ml_모델성능비교.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # 모델 성능 비교 저장\n",
    "    model_comparison.to_csv(f'{DATA_OUTPUT_DIR}/시계열_모델성능비교.csv', index=False)\n",
    "    print(f\"모델 성능 비교 결과가 '{DATA_OUTPUT_DIR}/시계열_모델성능비교.csv'에 저장되었습니다.\")\n",
    "    \n",
    "    # 최고 성능 모델 선택\n",
    "    best_model_name = model_comparison.iloc[model_comparison['Test R²'].argmax()]['Model']\n",
    "    best_model = model_results[best_model_name]['model']\n",
    "    \n",
    "    print(f\"\\n최고 성능 모델: {best_model_name}\")\n",
    "    print(f\"테스트 R²: {model_results[best_model_name]['test_r2']:.4f}\")\n",
    "    \n",
    "    # 특성 중요도 시각화 (해당되는 경우)\n",
    "    if best_model_name in ['RandomForest', 'XGBoost'] and hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(14, 10))\n",
    "        sns.barplot(x='importance', y='feature', data=feature_importance.head(20))\n",
    "        plt.title(f'{best_model_name} 특성 중요도 (상위 20개)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/ml_특성중요도.png')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n주요 특성 (상위 5개):\")\n",
    "        for i, (feature, importance) in enumerate(zip(feature_importance['feature'][:5], feature_importance['importance'][:5])):\n",
    "            print(f\"{i+1}. {feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28d90d1",
   "metadata": {},
   "source": [
    "## 10. 미래 예측\n",
    "선택된 최적 모델을 사용하여 학습 데이터 이후의 미래 기간에 대한 예측을 수행합니다.\n",
    "**주의**: 이 예측은 미래 시점의 실제 특성 값(lag, rolling 등)을 알 수 없다는 한계가 있습니다. 여기서는 단순화된 방식으로 과거 데이터를 기반으로 미래 특성을 추정하여 예측을 수행하므로, 실제 적용 시에는 예측 정확도에 한계가 있을 수 있습니다. 더 정확한 예측을 위해서는 반복적 예측(iterative forecasting) 등의 기법이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc5d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'best_model' in locals():\n",
    "    # 예측 기간 설정\n",
    "    last_date = X.index[-1]\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=FORECAST_HORIZON, freq='D')\n",
    "    \n",
    "    # 미래 데이터 특성 생성\n",
    "    # 참고: 아래 코드는 미래 시점의 특성을 생성하는 간단한 예시입니다.\n",
    "    #      실제로는 미래의 날짜 특성 외 다른 특성(lag, rolling 등)은 알 수 없으므로,\n",
    "    #      더 정확한 예측을 위해서는 예측된 값을 다시 입력으로 사용하는 반복적 예측(iterative forecasting)\n",
    "    #      또는 미래 특성을 예측하는 별도 모델링이 필요할 수 있습니다.\n",
    "    #      여기서는 교육적 목적을 위해 구현을 단순화했습니다.\n",
    "    future_df = pd.DataFrame(index=future_dates)\n",
    "    \n",
    "    # 미래 날짜 특성 생성\n",
    "    if USE_DATE_FEATURES:\n",
    "        future_df = create_date_features(future_df)\n",
    "    \n",
    "    # 최근 데이터를 사용하여 시차 특성 생성 (단순화된 방식)\n",
    "    if USE_LAG_FEATURES:\n",
    "        # 가장 최근 데이터(y)를 사용하여 미래 시점의 lag 특성 추정\n",
    "        recent_data = df[TARGET_COL].copy()\n",
    "        for i, date in enumerate(future_dates):\n",
    "            # 이 방식은 실제 미래 값을 모르므로 한계가 있음\n",
    "            for lag in LAG_PERIODS:\n",
    "                lag_idx = len(recent_data) - lag + i\n",
    "                # 과거 데이터가 있는 경우에만 사용, 없으면 NaN (추후 fillna)\n",
    "                future_df.loc[date, f'lag_{lag}'] = recent_data.iloc[lag_idx] if lag_idx >= 0 and lag_idx < len(recent_data) else np.nan\n",
    "\n",
    "    # 최근 데이터를 사용하여 이동 윈도우 특성 생성 (단순화된 방식)\n",
    "    if USE_ROLLING_FEATURES:\n",
    "        # 이 방식도 실제 미래 값을 모르므로 한계가 있음\n",
    "        # 가장 최근 rolling 값으로 채우거나, 다른 추정 방식 필요\n",
    "        # 여기서는 결측치 처리 단계에서 fillna(0) 등으로 처리됨\n",
    "        pass # Rolling 특성은 미래 시점 값을 예측하기 어려움\n",
    "\n",
    "    # 컬럼 순서 맞추기 (훈련 데이터와 동일하게)\n",
    "    for col in X.columns:\n",
    "        if col not in future_df.columns:\n",
    "            future_df[col] = np.nan # 없는 특성은 NaN으로 초기화\n",
    "    \n",
    "    future_df = future_df[X.columns]\n",
    "    \n",
    "    # 결측치 처리 (Lag, Rolling 등 미래를 알 수 없는 특성 처리)\n",
    "    # 주의: fillna(0)은 간단한 처리 방식이며, 데이터 특성에 따라 ffill, 평균값 등으로 변경 고려\n",
    "    future_df = future_df.fillna(0)\n",
    "    \n",
    "    # 전처리 적용\n",
    "    future_features_scaled = scaler.transform(future_df)\n",
    "    \n",
    "    # 예측\n",
    "    future_predictions = best_model.predict(future_features_scaled)\n",
    "    \n",
    "    # 예측 결과 데이터프레임 생성\n",
    "    forecast_df = pd.DataFrame({\n",
    "        'date': future_dates,\n",
    "        'forecast': future_predictions\n",
    "    }).set_index('date')\n",
    "    \n",
    "    # 최근 실제 데이터와 예측 시각화\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # 과거 데이터 (최근 90일)\n",
    "    history_period = min(90, len(df))\n",
    "    plt.plot(df.index[-history_period:], df[TARGET_COL][-history_period:], 'b-', label='과거 실제값')\n",
    "    \n",
    "    # 테스트 데이터의 예측값\n",
    "    plt.plot(y_test.index, model_results[best_model_name]['y_test_pred'], 'g--', label='테스트 예측값')\n",
    "    \n",
    "    # 미래 예측\n",
    "    plt.plot(forecast_df.index, forecast_df['forecast'], 'r--', label='미래 예측값')\n",
    "    \n",
    "    # 테스트/예측 구분선\n",
    "    plt.axvline(x=last_date, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.title(f'{best_model_name} 모델을 사용한 {FORECAST_HORIZON}일 예측')\n",
    "    plt.xlabel('날짜')\n",
    "    plt.ylabel(TARGET_COL)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/ml_미래예측.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # 예측 결과 저장\n",
    "    forecast_df.to_csv(f'{DATA_OUTPUT_DIR}/시계열_예측결과.csv')\n",
    "    print(f\"예측 결과가 '{DATA_OUTPUT_DIR}/시계열_예측결과.csv'에 저장되었습니다.\")\n",
    "    \n",
    "    # 예측 요약\n",
    "    print(\"\\n===== 예측 요약 =====\")\n",
    "    print(f\"예측 기간: {forecast_df.index[0].strftime('%Y-%m-%d')} ~ {forecast_df.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"예측 범위: {forecast_df['forecast'].min():.4f} ~ {forecast_df['forecast'].max():.4f}\")\n",
    "    print(f\"평균 예측값: {forecast_df['forecast'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa6606",
   "metadata": {},
   "source": [
    "## 11. 결론 및 인사이트\n",
    "전체 분석 과정과 모델 성능 결과를 요약하고, 데이터 특성, 사용된 특성, 최적 모델 및 성능 등에 대한 인사이트를 정리합니다. 향후 모델 개선 방향이나 추가 분석 아이디어를 제시할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e07c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model_results' in locals() and model_results:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"시계열 머신러닝 모델링 요약\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\n1. 데이터 정보:\")\n",
    "    print(f\"   - 데이터 포인트 수: {len(df)}\")\n",
    "    print(f\"   - 사용된 특성 수: {X.shape[1]}\")\n",
    "    \n",
    "    print(f\"\\n2. 모델 성능:\")\n",
    "    for model_name, results in model_results.items():\n",
    "        print(f\"   - {model_name}: 테스트 RMSE = {results['test_rmse']:.4f}, R² = {results['test_r2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n3. 최고 성능 모델: {best_model_name}\")\n",
    "    print(f\"   - 테스트 R²: {model_results[best_model_name]['test_r2']:.4f}\")\n",
    "    print(f\"   - 테스트 RMSE: {model_results[best_model_name]['test_rmse']:.4f}\")\n",
    "    \n",
    "    print(\"\\n시계열 머신러닝 모델링이 완료되었습니다!\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
