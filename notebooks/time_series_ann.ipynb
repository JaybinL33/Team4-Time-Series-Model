{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2cc7559",
   "metadata": {},
   "source": [
    "# 시계열 분석 - 인공신경망 모델 (ANN)\n",
    "## Team 4\n",
    "\n",
    "이 노트북은 기본 인공신경망(ANN, 여기서는 Multi-Layer Perceptron, MLP)을 사용하여 시계열 예측을 수행하는 과정을 보여줍니다.\n",
    "ANN/MLP는 입력 특성(여기서는 과거 시점의 값, 날짜 정보 등)과 타겟 변수 간의 비선형 관계를 학습할 수 있는 기본적인 딥러닝 모델입니다.\n",
    "LSTM과 달리 시간적 순서를 직접 고려하지는 않지만, 적절한 특성 엔지니어링을 통해 시계열 예측에 활용될 수 있습니다.\n",
    "\n",
    "## 분석 흐름\n",
    "1. **문제 정의 및 목표 설정**: 예측 대상, 목표, 평가 지표를 정의합니다.\n",
    "2. **데이터 탐색 및 전처리**: 데이터를 로드하고 패턴을 탐색하며, 결측치 처리, 특성 엔지니어링, 스케일링, 데이터 분할을 수행합니다.\n",
    "3. **모델 선택 및 구현 (ANN/MLP)**: 다양한 구조의 MLP 모델을 정의하고 컴파일합니다.\n",
    "4. **모델 학습 및 평가**: 모델을 학습시키고 검증/테스트 데이터로 성능을 평가하며 학습 곡선을 확인합니다.\n",
    "5. **모델 비교**: 여러 MLP 모델의 성능을 비교하여 최적 모델을 선정합니다.\n",
    "6. **결과 해석 및 인사이트 도출**: 최적 모델의 예측 결과를 분석하고, 미래 예측 시뮬레이션(단순화된 방식)을 수행하며 인사이트를 도출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ca839",
   "metadata": {},
   "source": [
    "## 1. 문제 정의 및 목표 설정\n",
    "\n",
    "이 템플릿은 기본적인 MLP 모델을 이용한 시계열 예측의 기본 구조를 제공합니다.\n",
    "\n",
    "**목표:**\n",
    "- MLP 모델을 사용하여 시계열 데이터를 예측합니다.\n",
    "- **윈도우 기반 특성 엔지니어링**: 과거 시점의 값(lag), 날짜 정보, 이동 통계량 등을 특성으로 변환하여 MLP 모델의 입력으로 사용합니다.\n",
    "- 다양한 MLP 모델 구조(은닉층 수, 뉴런 수, 활성화 함수 등)를 실험하고 비교합니다.\n",
    "- 간단한 딥러닝 모델로서의 성능 기준점을 확인합니다.\n",
    "\n",
    "**평가 지표:** RMSE, MAE, R² Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18a4bc",
   "metadata": {},
   "source": [
    "### 사용자 파라미터 설정\n",
    "분석 데이터, 모델 구조, 학습 파라미터를 설정합니다.\n",
    "MLP 모델은 입력으로 사용할 특성을 정의하는 `WINDOW_SIZE` 파라미터가 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 파라미터\n",
    "DATA_PATH = \"../data/raw/your_data.csv\"   # 데이터 파일 경로\n",
    "DATE_COL = \"date\"                         # 날짜 컬럼명\n",
    "TARGET_COL = \"value\"                      # 예측할 타겟 컬럼명\n",
    "TRAIN_SIZE = 0.7                          # 훈련 데이터 비율\n",
    "VALIDATION_SIZE = 0.1                     # 검증 데이터 비율 (7:1:2 분할)\n",
    "\n",
    "# 모델 파라미터\n",
    "WINDOW_SIZE = 7                           # 입력 윈도우 크기 (과거 며칠의 데이터로 예측할지)\n",
    "EPOCHS = 100                              # 최대 학습 에폭\n",
    "BATCH_SIZE = 32                           # 배치 크기\n",
    "PATIENCE = 20                             # 조기 종료 파라미터\n",
    "FORECAST_HORIZON = 30                     # 미래 예측 기간 (일 단위 등)\n",
    "RANDOM_STATE = 42                         # 랜덤 시드 (재현성을 위해 추가)\n",
    "\n",
    "# 출력 디렉토리\n",
    "OUTPUT_DIR = '../plots'                   # 시각화 결과 저장 경로\n",
    "DATA_OUTPUT_DIR = '../data/processed'     # 전처리된 데이터 저장 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e039769",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 임포트\n",
    "데이터 처리, 시각화, 시계열 분석, 딥러닝 모델링(TensorFlow/Keras)에 필요한 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f50500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import tensorflow as tf\n",
    "# Keras를 독립 패키지로 사용\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "import statsmodels.tsa.api as tsa\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 랜덤 시드 설정 (결과 재현성을 위해)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "keras.utils.set_random_seed(RANDOM_STATE)  # keras 시드 설정 추가\n",
    "\n",
    "# 그래프 스타일 설정\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# 결과 저장 디렉토리 생성 코드 제거\n",
    "# 프로젝트 지침에 따라 필요 폴더는 이미 존재한다고 가정\n",
    "\n",
    "# # GPU 메모리 설정 (필요시 주석 해제 및 환경에 맞게 설정)\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         print(\"GPU 메모리 증가 설정 완료\")\n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"GPU 설정 오류: {e}\")\n",
    "# else:\n",
    "#     print(\"사용 가능한 GPU가 없습니다. CPU를 사용합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d63df",
   "metadata": {},
   "source": [
    "## 2. 데이터 탐색 및 전처리\n",
    "MLP 모델 학습을 위한 데이터를 준비하는 과정입니다.\n",
    "데이터 로드, 기본 정보 확인, 결측치 처리, 시각화를 통한 패턴 분석, 특성 생성, 스케일링, 데이터 분할 등을 포함합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba11f084",
   "metadata": {},
   "source": [
    "### 2.1 데이터 로드 및 기본 탐색\n",
    "지정된 경로에서 데이터를 로드하고, 날짜 인덱스 설정, 타겟 변수 확인 및 기본 정보를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e949d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 (사용자가 제공한 경로)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"데이터를 성공적으로 로드했습니다. 크기: {df.shape}\")\n",
    "\n",
    "# 날짜 열 처리 (사용자 지정 컬럼 사용)\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "df.set_index(DATE_COL, inplace=True)\n",
    "print(f\"'{DATE_COL}' 열을 인덱스로 설정했습니다.\")\n",
    "\n",
    "# 타겟 변수 확인 (사용자 지정 컬럼 사용)\n",
    "if TARGET_COL not in df.columns:\n",
    "    # TARGET_COL이 없는 경우 오류 발생 또는 경고 후 첫 번째 숫자형 컬럼 사용 등의 처리가 필요하나,\n",
    "    # 템플릿 단순화를 위해 사용자가 올바른 컬럼명을 제공하는 것을 전제합니다.\n",
    "    print(f\"경고: 지정된 타겟 컬럼 '{TARGET_COL}'이 데이터에 없습니다. 첫 번째 숫자형 컬럼을 사용하거나 코드를 수정하세요.\")\n",
    "    # 또는 raise ValueError(f\"Target column '{TARGET_COL}' not found in data.\")\n",
    "\n",
    "print(f\"\\n타겟 변수: {TARGET_COL}\")\n",
    "\n",
    "# 데이터 요약 정보\n",
    "print(\"\\n데이터 기본 정보:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n기술 통계량:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 데이터 처음과 끝 확인\n",
    "print(\"\\n데이터 처음 5행:\")\n",
    "print(df.head())\n",
    "print(\"\\n데이터 마지막 5행:\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552c654",
   "metadata": {},
   "source": [
    "### 2.2 시계열 시각화 및 패턴 분석\n",
    "전처리된 데이터를 시각화하여 패턴을 분석하고, 정상성 여부를 확인합니다.\n",
    "- **시계열 플롯**: 시간에 따른 데이터 변화 추세를 확인합니다.\n",
    "- **결측치 처리**: 선형 보간법을 사용하여 결측치를 채웁니다.\n",
    "- **ACF/PACF 플롯**: 데이터의 자기상관 구조를 파악합니다.\n",
    "- **ADF 검정**: 시계열의 정상성을 통계적으로 검정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 시계열 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df.index, df[TARGET_COL])\n",
    "plt.title('시계열 데이터')\n",
    "plt.xlabel('날짜')\n",
    "plt.ylabel(TARGET_COL)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ann_시계열데이터.png')\n",
    "plt.show()\n",
    "\n",
    "# 결측치 확인 및 처리\n",
    "print(\"\\n결측치 개수:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 시나리오 A: 결측치가 있는 경우 - 선형 보간법으로 처리\n",
    "# 시계열의 연속성을 최대한 유지하면서 결측치를 채우는 방법\n",
    "# 대부분의 시계열 분석에서 권장되는 기본 접근법\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.interpolate(method='time')\n",
    "    \n",
    "# 시작/끝에 결측치가 남아있을 경우\n",
    "if df_clean.isnull().sum().sum() > 0:\n",
    "    df_clean = df_clean.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "print(f\"결측치 처리 완료. 남은 결측치: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "# 시나리오 B: 결측치가 없는 경우 (주석 처리됨)\n",
    "# df_clean = df.copy()\n",
    "# print(\"결측치가 없습니다.\")\n",
    "\n",
    "# 시계열 분석 - ACF, PACF\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(211)\n",
    "plot_acf(df_clean[TARGET_COL].dropna(), lags=40, ax=plt.gca())\n",
    "plt.title('자기상관함수(ACF)')\n",
    "\n",
    "plt.subplot(212)\n",
    "plot_pacf(df_clean[TARGET_COL].dropna(), lags=40, ax=plt.gca())\n",
    "plt.title('편자기상관함수(PACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ann_자기상관.png')\n",
    "plt.show()\n",
    "\n",
    "# 정상성 검정\n",
    "adf_result = adfuller(df_clean[TARGET_COL].dropna())\n",
    "print('ADF 테스트 결과:')\n",
    "print(f'ADF 통계값: {adf_result[0]:.4f}')\n",
    "print(f'p-value: {adf_result[1]:.4f}')\n",
    "print('임계값:')\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f'   {key}: {value:.4f}')\n",
    "\n",
    "is_stationary = adf_result[1] < 0.05\n",
    "print(f\"시계열 정상성 여부: {'정상적일 가능성 높음 (p < 0.05)' if is_stationary else '비정상적일 가능성 높음 (p >= 0.05)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ca4c8",
   "metadata": {},
   "source": [
    "### 2.3 특성 엔지니어링 및 윈도우 생성\n",
    "시계열 데이터를 MLP 모델의 입력 특성으로 변환하는 과정입니다.\n",
    "- **특성 생성**: 날짜 기반 특성, 시차(lag) 특성, 이동(rolling) 특성 등을 생성합니다. `WINDOW_SIZE`는 시차 및 이동 특성 생성에 사용되는 과거 기간을 의미합니다.\n",
    "- **결측치 처리**: 특성 생성 과정에서 발생하는 초기 결측치를 제거합니다.\n",
    "- **데이터 스케일링**: 생성된 특성(X)과 타겟(y)을 각각 적절한 스케일러(`StandardScaler`, `MinMaxScaler`)로 변환합니다.\n",
    "- **데이터 분할**: 스케일링된 특성 데이터를 훈련, 검증, 테스트 세트로 분할합니다. 시계열 데이터의 순서를 유지합니다.\n",
    "**주의**: MLP 모델은 LSTM과 달리 시퀀스 형태의 입력이 필요하지 않으므로, `create_sequences` 함수를 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3884e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 시나리오 A: 시간 관련 특성 추가 (DatetimeIndex가 있는 경우)\n",
    "# 시간 정보에서 다양한 특성 추출하여 모델 성능 향상\n",
    "if isinstance(df_clean.index, pd.DatetimeIndex):\n",
    "    print(\"시간 관련 특성 추가 중...\")\n",
    "    # 원본 데이터 복사\n",
    "    df_features = df_clean.copy()\n",
    "    \n",
    "    # 시간 관련 특성\n",
    "    df_features['dayofweek'] = df_features.index.dayofweek\n",
    "    df_features['month'] = df_features.index.month\n",
    "    df_features['year'] = df_features.index.year\n",
    "    \n",
    "    # 시간 특성 사인/코사인 변환 (주기성 포착)\n",
    "    df_features['dayofweek_sin'] = np.sin(2 * np.pi * df_features.index.dayofweek / 7)\n",
    "    df_features['dayofweek_cos'] = np.cos(2 * np.pi * df_features.index.dayofweek / 7)\n",
    "    df_features['month_sin'] = np.sin(2 * np.pi * df_features.index.month / 12)\n",
    "    df_features['month_cos'] = np.cos(2 * np.pi * df_features.index.month / 12)\n",
    "    \n",
    "    # 시차 특성 (이전 시점의 값)\n",
    "    for i in range(1, WINDOW_SIZE + 1):\n",
    "        df_features[f'lag_{i}'] = df_features[TARGET_COL].shift(i)\n",
    "    \n",
    "    # 이동 평균 및 표준편차\n",
    "    df_features['rolling_mean_7'] = df_features[TARGET_COL].rolling(window=7).mean()\n",
    "    df_features['rolling_std_7'] = df_features[TARGET_COL].rolling(window=7).std()\n",
    "    \n",
    "    print(\"생성된 특성:\")\n",
    "    print(df_features.columns.tolist())\n",
    "    \n",
    "    # 결측치 처리\n",
    "    df_features = df_features.dropna()\n",
    "    print(f\"특성 생성 완료. 최종 데이터 크기: {df_features.shape}\")\n",
    "else:\n",
    "    # 시나리오 B: DatetimeIndex가 없는 경우 (단순 시차 변수만 생성)\n",
    "    print(\"DatetimeIndex가 없어 단순 시차 변수만 생성합니다.\")\n",
    "    \n",
    "    df_features = df_clean.copy()\n",
    "    for i in range(1, WINDOW_SIZE + 1):\n",
    "        df_features[f'lag_{i}'] = df_features[TARGET_COL].shift(i)\n",
    "    \n",
    "    # 결측치 처리\n",
    "    df_features = df_features.dropna()\n",
    "    print(f\"특성 생성 완료. 최종 데이터 크기: {df_features.shape}\")\n",
    "\n",
    "# 데이터 스케일링\n",
    "print(\"\\n데이터 스케일링...\")\n",
    "# 타겟 변수와 특성 분리\n",
    "X = df_features.drop(columns=[TARGET_COL])\n",
    "y = df_features[TARGET_COL]\n",
    "\n",
    "# 특성 스케일링\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# 타겟 스케일링\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 데이터 분할\n",
    "train_size = int(len(X_scaled) * TRAIN_SIZE)\n",
    "val_size = int(len(X_scaled) * VALIDATION_SIZE)\n",
    "test_size = len(X_scaled) - train_size - val_size\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 분할 (7:1:2 비율)\n",
    "X_train = X_scaled[:train_size]\n",
    "y_train = y_scaled[:train_size]\n",
    "\n",
    "X_val = X_scaled[train_size:train_size+val_size]\n",
    "y_val = y_scaled[train_size:train_size+val_size]\n",
    "\n",
    "X_test = X_scaled[train_size+val_size:]\n",
    "y_test = y_scaled[train_size+val_size:]\n",
    "\n",
    "print(f\"훈련 데이터: X:{X_train.shape}, y:{y_train.shape} (70%)\")\n",
    "print(f\"검증 데이터: X:{X_val.shape}, y:{y_val.shape} (10%)\")\n",
    "print(f\"테스트 데이터: X:{X_test.shape}, y:{y_test.shape} (20%)\")\n",
    "\n",
    "# 데이터 분할 시각화 (원본 값 기준)\n",
    "original_dates = df_features.index\n",
    "train_dates = original_dates[:train_size]\n",
    "val_dates = original_dates[train_size:train_size+val_size]\n",
    "test_dates = original_dates[train_size+val_size:]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_dates, df_features.iloc[:train_size][TARGET_COL], label='훈련 데이터 (70%)')\n",
    "plt.plot(val_dates, df_features.iloc[train_size:train_size+val_size][TARGET_COL], label='검증 데이터 (10%)')\n",
    "plt.plot(test_dates, df_features.iloc[train_size+val_size:][TARGET_COL], label='테스트 데이터 (20%)')\n",
    "plt.title('데이터 분할 (7:1:2 비율)')\n",
    "plt.xlabel('날짜')\n",
    "plt.ylabel(TARGET_COL)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ann_데이터분할.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce1551a",
   "metadata": {},
   "source": [
    "## 3. 모델 선택 및 구현\n",
    "기본적인 MLP 모델 구조를 정의하고 학습 준비를 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1d494e",
   "metadata": {},
   "source": [
    "### 3.1 인공신경망 모델 정의\n",
    "Keras Sequential API를 사용하여 다양한 구조의 MLP 모델을 정의하는 함수들을 만듭니다.\n",
    "- **Dense 레이어**: 완전 연결 레이어. `units`는 뉴런 수, `activation`은 활성화 함수(예: 'relu')를 지정합니다.\n",
    "- **BatchNormalization**: 학습 안정화 및 속도 향상.\n",
    "- **Dropout**: 과적합 방지.\n",
    "모델 구성(Simple, Deep, Complex)을 리스트로 정의하여 비교 실험을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f96852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 ANN 모델 정의\n",
    "def build_simple_ann(input_dim):\n",
    "    \"\"\"\n",
    "    간단한 단층 신경망 모델\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_dim=input_dim),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_deep_ann(input_dim):\n",
    "    \"\"\"\n",
    "    다층 신경망 모델\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        BatchNormalization(),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_complex_ann(input_dim):\n",
    "    \"\"\"\n",
    "    드롭아웃을 포함한 복잡한 신경망 모델\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 다양한 모델 구성\n",
    "ann_models = [\n",
    "    {'name': 'SimpleANN', 'build_fn': build_simple_ann},\n",
    "    {'name': 'DeepANN', 'build_fn': build_deep_ann},\n",
    "    {'name': 'ComplexANN', 'build_fn': build_complex_ann}\n",
    "]\n",
    "\n",
    "# 콜백 함수 설정\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=PATIENCE//2,\n",
    "        min_lr=0.0001,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd83df",
   "metadata": {},
   "source": [
    "### 3.2 모델 학습\n",
    "정의된 각 MLP 모델 구성에 대해 다음 과정을 반복합니다:\n",
    "1. 모델 생성 (해당 `build_xxx_ann` 함수 호출)\n",
    "2. 모델 아키텍처 확인 (`model.summary()`)\n",
    "3. 모델 학습 (`model.fit()`): 훈련 데이터(X_train_scaled, y_train)로 학습하고, 검증 데이터(X_val_scaled, y_val)로 성능을 모니터링합니다. 콜백 함수가 적용됩니다.\n",
    "4. 학습 곡선 시각화: 훈련/검증 손실 변화를 확인합니다.\n",
    "5. 모델 저장 (선택 사항)\n",
    "6. 학습된 모델 객체 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be06014",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 모델 성능 저장 리스트\n",
    "model_performances = []\n",
    "\n",
    "# 각 모델 학습 및 평가\n",
    "for model_config in ann_models:\n",
    "    model_name = model_config['name']\n",
    "    print(f\"\\n{model_name} 모델 학습 시작...\")\n",
    "    \n",
    "    # 모델 생성\n",
    "    model = model_config['build_fn'](X_train.shape[1])\n",
    "    \n",
    "    # 모델 아키텍처 출력\n",
    "    model.summary()\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 학습 곡선 시각화\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(history.history['loss'], label='훈련 손실')\n",
    "    plt.plot(history.history['val_loss'], label='검증 손실')\n",
    "    plt.title(f'{model_name} - 학습 곡선')\n",
    "    plt.xlabel('에포크')\n",
    "    plt.ylabel('손실 (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/ann_{model_name}_학습곡선.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # 모델 저장 (선택 사항)\n",
    "    model.save(f'{DATA_OUTPUT_DIR}/ann_{model_name}.h5')\n",
    "    print(f\"{model_name} 모델이 '{DATA_OUTPUT_DIR}/ann_{model_name}.h5'에 저장되었습니다.\")\n",
    "    \n",
    "    # 모델 성능 저장\n",
    "    model_performances.append({\n",
    "        'name': model_name,\n",
    "        'model': model\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f8deef",
   "metadata": {},
   "source": [
    "## 4. 모델 평가 및 비교\n",
    "학습된 모델들의 성능을 평가하고 비교합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad91d7e",
   "metadata": {},
   "source": [
    "### 4.1 모델 평가 함수\n",
    "스케일링된 예측값을 원래 스케일로 변환하고, 성능 지표(RMSE, MAE, R²)를 계산하며, 예측 결과를 시각화하는 함수(`evaluate_model`)를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc1c3b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, dates=None, model_name='모델'):\n",
    "    \"\"\"\n",
    "    모델 성능 평가 함수\n",
    "    \n",
    "    Args:\n",
    "        model: 학습된 모델\n",
    "        X: 입력 특성\n",
    "        y: 타겟 값 (스케일링된)\n",
    "        dates: 날짜 인덱스 (선택 사항)\n",
    "        model_name: 모델 이름\n",
    "        \n",
    "    Returns:\n",
    "        mse, rmse, mae, r2, y_pred_orig: 평가 지표와 원래 스케일의 예측 값\n",
    "    \"\"\"\n",
    "    # 예측 수행\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # 스케일링된 성능 지표\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    \n",
    "    # 원래 스케일로 변환\n",
    "    y_true_orig = scaler_y.inverse_transform(y.reshape(-1, 1)).flatten()\n",
    "    y_pred_orig = scaler_y.inverse_transform(y_pred).flatten()\n",
    "    \n",
    "    # 원래 스케일의 성능 지표\n",
    "    orig_mse = mean_squared_error(y_true_orig, y_pred_orig)\n",
    "    orig_rmse = np.sqrt(orig_mse)\n",
    "    orig_mae = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    r2 = r2_score(y_true_orig, y_pred_orig)\n",
    "    \n",
    "    print(f\"\\n{model_name} 모델 평가:\")\n",
    "    print(f\"MSE: {orig_mse:.4f}\")\n",
    "    print(f\"RMSE: {orig_rmse:.4f}\")\n",
    "    print(f\"MAE: {orig_mae:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    # 시각화 (날짜 제공된 경우)\n",
    "    if dates is not None:\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(dates, y_true_orig, label='실제값')\n",
    "        plt.plot(dates, y_pred_orig, label='예측값', alpha=0.7)\n",
    "        plt.title(f'{model_name} - 예측 결과')\n",
    "        plt.xlabel('날짜')\n",
    "        plt.ylabel(TARGET_COL)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/ann_{model_name}_예측.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # 산점도 (실제값 vs 예측값)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.scatter(y_true_orig, y_pred_orig, alpha=0.5)\n",
    "        plt.plot([y_true_orig.min(), y_true_orig.max()], \n",
    "                [y_true_orig.min(), y_true_orig.max()], \n",
    "                'r--', lw=2)\n",
    "        plt.title(f'{model_name} - 실제값 vs 예측값')\n",
    "        plt.xlabel('실제값')\n",
    "        plt.ylabel('예측값')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/ann_{model_name}_산점도.png')\n",
    "        plt.show()\n",
    "    \n",
    "    return orig_rmse, orig_mae, r2, y_pred_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb3cd1",
   "metadata": {},
   "source": [
    "### 4.2 모델 성능 평가\n",
    "저장된 각 모델 객체를 사용하여 검증 및 테스트 데이터에 대한 예측을 수행하고, `evaluate_model` 함수를 호출하여 성능 지표를 계산 및 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa69a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 모델 평가\n",
    "all_metrics = []\n",
    "\n",
    "for model_info in model_performances:\n",
    "    model = model_info['model']\n",
    "    model_name = model_info['name']\n",
    "    \n",
    "    # 검증 데이터 평가\n",
    "    val_rmse, val_mae, val_r2, val_pred = evaluate_model(\n",
    "        model, X_val, y_val, val_dates, f\"{model_name} (검증)\"\n",
    "    )\n",
    "    \n",
    "    # 테스트 데이터 평가\n",
    "    test_rmse, test_mae, test_r2, test_pred = evaluate_model(\n",
    "        model, X_test, y_test, test_dates, f\"{model_name} (테스트)\"\n",
    "    )\n",
    "    \n",
    "    # 성능 저장\n",
    "    all_metrics.append({\n",
    "        'model': model_name,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_mae': val_mae,\n",
    "        'val_r2': val_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'test_r2': test_r2\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16289f1",
   "metadata": {},
   "source": [
    "### 4.3 모델 비교\n",
    "계산된 성능 지표를 바탕으로 여러 MLP 모델 간의 성능을 비교합니다.\n",
    "- **성능 비교 테이블 및 시각화**: 테스트 성능 지표를 표와 그래프로 나타내어 비교합니다.\n",
    "- **최고 성능 모델 선택**: 테스트 RMSE가 가장 낮은 모델을 최적 모델로 선정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a83ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 비교 테이블\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "print(\"\\n모델 성능 비교:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# 모델 비교 시각화\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.bar(metrics_df['model'], metrics_df['test_rmse'])\n",
    "plt.title('테스트 RMSE (낮을수록 좋음)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.bar(metrics_df['model'], metrics_df['test_mae'])\n",
    "plt.title('테스트 MAE (낮을수록 좋음)')\n",
    "plt.ylabel('MAE')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.bar(metrics_df['model'], metrics_df['test_r2'])\n",
    "plt.title('테스트 R² (높을수록 좋음)')\n",
    "plt.ylabel('R²')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.bar(metrics_df['model'], metrics_df['val_rmse'])\n",
    "plt.title('검증 RMSE (낮을수록 좋음)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ann_모델비교.png')\n",
    "plt.show()\n",
    "\n",
    "# 최고 성능 모델 선택\n",
    "best_model_idx = metrics_df['test_rmse'].idxmin()\n",
    "best_model_name = metrics_df.loc[best_model_idx, 'model']\n",
    "best_model = model_performances[best_model_idx]['model']\n",
    "best_rmse = metrics_df.loc[best_model_idx, 'test_rmse']\n",
    "best_r2 = metrics_df.loc[best_model_idx, 'test_r2']\n",
    "\n",
    "print(f\"\\n최고 성능 모델: {best_model_name}\")\n",
    "print(f\"테스트 RMSE: {best_rmse:.4f}\")\n",
    "print(f\"테스트 R²: {best_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed1785",
   "metadata": {},
   "source": [
    "### 4.4 시계열 교차 검증 (Time Series Cross-Validation)\n",
    "본 분석에서는 기본적인 훈련/검증/테스트 분할 방식을 사용했습니다. 더 견고한 모델 평가를 위해 시계열 교차 검증을 추가로 수행합니다.\n",
    "시계열 데이터에서는 일반적인 k-fold 교차 검증이 아닌, 시간적 의존성을 고려한 `TimeSeriesSplit`을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa932c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 교차 검증 설정\n",
    "print(\"\\n시계열 교차 검증 수행...\")\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 스케일링된 전체 데이터\n",
    "X_all = np.concatenate([X_train, X_val, X_test])\n",
    "y_all = np.concatenate([y_train, y_val, y_test])\n",
    "\n",
    "# 최적 모델 구성 선택\n",
    "best_model_config = ann_models[best_model_idx]['build_fn']\n",
    "cv_scores = []\n",
    "\n",
    "# 교차 검증 시각화 준비\n",
    "plt.figure(figsize=(14, 7))\n",
    "for i, (train_idx, test_idx) in enumerate(tscv.split(X_all)):\n",
    "    # 훈련/테스트 분할\n",
    "    X_cv_train, X_cv_test = X_all[train_idx], X_all[test_idx]\n",
    "    y_cv_train, y_cv_test = y_all[train_idx], y_all[test_idx]\n",
    "    \n",
    "    # 모델 생성 및 학습\n",
    "    cv_model = best_model_config(X_train.shape[1])\n",
    "    cv_model.fit(\n",
    "        X_cv_train, y_cv_train,\n",
    "        epochs=EPOCHS // 2,  # 시간 단축을 위해 에포크 감소\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 예측 및 스케일 변환\n",
    "    y_cv_pred = cv_model.predict(X_cv_test, verbose=0)\n",
    "    \n",
    "    # 원래 스케일로 변환\n",
    "    y_cv_true_orig = scaler_y.inverse_transform(y_cv_test.reshape(-1, 1)).flatten()\n",
    "    y_cv_pred_orig = scaler_y.inverse_transform(y_cv_pred).flatten()\n",
    "    \n",
    "    # 성능 평가\n",
    "    cv_rmse = np.sqrt(mean_squared_error(y_cv_true_orig, y_cv_pred_orig))\n",
    "    cv_scores.append(cv_rmse)\n",
    "    \n",
    "    # 시각화\n",
    "    plt.subplot(5, 1, i+1)\n",
    "    plt.plot(y_cv_true_orig[:40], label='실제값')  # 처음 40개 포인트만 표시\n",
    "    plt.plot(y_cv_pred_orig[:40], label='예측값', alpha=0.7)\n",
    "    plt.title(f'Fold {i+1} - RMSE: {cv_rmse:.4f}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ann_교차검증.png')\n",
    "plt.show()\n",
    "\n",
    "# 교차 검증 결과 요약\n",
    "print(f\"\\n교차 검증 결과 (5-fold TimeSeriesSplit):\")\n",
    "print(f\"평균 RMSE: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"표준편차: {np.std(cv_scores):.4f}\")\n",
    "print(f\"최소 RMSE: {np.min(cv_scores):.4f}\")\n",
    "print(f\"최대 RMSE: {np.max(cv_scores):.4f}\")\n",
    "\n",
    "# 교차 검증 성능 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(cv_scores)\n",
    "plt.title('교차 검증 RMSE 분포')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(f'{OUTPUT_DIR}/ann_교차검증_분포.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa313466",
   "metadata": {},
   "source": [
    "## 5. 결과 해석 및 인사이트 도출\n",
    "최종 분석 결과와 모델 성능을 요약하고 해석합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721aab0",
   "metadata": {},
   "source": [
    "### 5.1 미래 예측 시뮬레이션\n",
    "선택된 최적 MLP 모델을 사용하여 미래 기간(`FORECAST_HORIZON`)에 대한 예측을 수행합니다.\n",
    "**주의**: 이 예측은 미래 시점의 실제 특성 값을 알 수 없으므로, 마지막 관측 시점의 특성 벡터를 그대로 사용하여 예측하는 **단순화된 방식**입니다. 이는 MLP 모델의 일반적인 미래 예측 방식 중 하나이지만, 정확도에 한계가 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미래 예측을 위한 예시\n",
    "print(\"\\n미래 예측 시뮬레이션\")\n",
    "print(\"참고: 아래 코드는 미래 예측을 위한 단순화된 접근 방식입니다.\")\n",
    "print(\"      실제 미래의 특성 값(lag, rolling 등)은 알 수 없으므로,\")\n",
    "print(\"      과거 데이터 기반으로 추정하거나 마지막 값을 사용합니다.\")\n",
    "print(\"      더 정확한 예측을 위해서는 반복적 예측 또는 미래 특성 모델링이 필요할 수 있습니다.\")\n",
    "\n",
    "# 예측 기간 설정 (파라미터 사용)\n",
    "# forecast_horizon = 30  # 기존 하드코딩 제거\n",
    "\n",
    "# 마지막 입력 데이터 가져오기 (스케일링 된 상태)\n",
    "last_x_scaled = X_test[-1].reshape(1, -1)\n",
    "\n",
    "# 미래 날짜 생성\n",
    "last_date = df_features.index[-1]\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=FORECAST_HORIZON)\n",
    "\n",
    "# 예측 함수 (단순화된 방식: 마지막 특성 반복 사용)\n",
    "def forecast_simple(model, last_features_scaled, n_steps, scaler_y):\n",
    "    \"\"\" 마지막 특성 벡터를 반복 사용하여 미래 값을 예측합니다. \"\"\"\n",
    "    # 마지막 특성 벡터를 예측 기간만큼 복제\n",
    "    future_features = np.tile(last_features_scaled, (n_steps, 1))\n",
    "    \n",
    "    # 예측 수행 (스케일링된 값)\n",
    "    future_predictions_scaled = model.predict(future_features)\n",
    "    \n",
    "    # 원래 스케일로 변환\n",
    "    future_predictions_original = scaler_y.inverse_transform(future_predictions_scaled).flatten()\n",
    "    \n",
    "    return future_predictions_original\n",
    "\n",
    "# 최적 모델을 사용한 예측 (단순화된 방식)\n",
    "future_values = forecast_simple(\n",
    "    best_model, last_x_scaled, FORECAST_HORIZON, scaler_y # 파라미터 사용\n",
    ")\n",
    "\n",
    "# 예측 결과 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "# 과거 데이터 (마지막 90일)\n",
    "history_days = 90\n",
    "past_dates = df_features.index[-history_days:]\n",
    "past_values = df_features[TARGET_COL][-history_days:]\n",
    "\n",
    "plt.plot(past_dates, past_values, label='과거 데이터', color='blue')\n",
    "plt.plot(future_dates, future_values, label='미래 예측', color='red', linestyle='--')\n",
    "plt.axvline(x=last_date, color='green', linestyle='-', label='현재')\n",
    "plt.title(f'{best_model_name} - {FORECAST_HORIZON}일 미래 예측 시뮬레이션') # 시각화 제목에도 파라미터 적용\n",
    "plt.xlabel('날짜')\n",
    "plt.ylabel(TARGET_COL)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/ann_미래예측.png')\n",
    "plt.show()\n",
    "\n",
    "# 예측 결과를 DataFrame으로 변환\n",
    "forecast_df = pd.DataFrame({\n",
    "    'date': future_dates,\n",
    "    f'{TARGET_COL}_forecast': future_values\n",
    "})\n",
    "\n",
    "print(\"\\n미래 예측 결과 (처음 10일):\")\n",
    "print(forecast_df.head(10))\n",
    "\n",
    "# 예측 결과 저장\n",
    "forecast_df.to_csv(f'{DATA_OUTPUT_DIR}/ann_forecast_results.csv', index=False)\n",
    "print(f\"예측 결과가 '{DATA_OUTPUT_DIR}/ann_forecast_results.csv'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc7848",
   "metadata": {},
   "source": [
    "### 5.2 결론 및 인사이트\n",
    "전체 분석 과정과 결과를 요약합니다.\n",
    "- 최적 모델과 그 성능을 제시합니다.\n",
    "- 모델 구조(단순/복잡)와 성능 간의 관계를 해석합니다.\n",
    "- ANN 모델의 특성 중요도 분석의 어려움과 대안을 언급합니다.\n",
    "- 입력 윈도우 크기의 영향을 설명합니다.\n",
    "- 향후 개선 방향(하이퍼파라미터 튜닝, 특성 조정, 다른 모델 비교 등)을 제안합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37104b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"결론 및 인사이트\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 모델 성능 요약\n",
    "print(f\"1. 최적의 모델: {best_model_name}\")\n",
    "print(f\"2. 테스트 RMSE: {best_rmse:.4f}\")\n",
    "print(f\"3. 테스트 R²: {best_r2:.4f}\")\n",
    "\n",
    "# 모델 특성\n",
    "if best_model_name == 'SimpleANN':\n",
    "    print(\"\\n단순 구조 모델이 최적 성능을 보였습니다:\")\n",
    "    print(\"- 데이터의 패턴이 비교적 단순하거나 모델의 과적합이 발생했을 수 있습니다.\")\n",
    "    print(\"- 단순 모델은 일반화 능력이 더 좋은 경우가 많습니다.\")\n",
    "elif best_model_name == 'DeepANN':\n",
    "    print(\"\\n중간 깊이의 모델이 최적 성능을 보였습니다:\")\n",
    "    print(\"- 모델 복잡성과 일반화 능력 사이의 균형이 잘 맞았습니다.\")\n",
    "    print(\"- 다층 구조가 데이터의 비선형 패턴을 더 잘 포착했습니다.\")\n",
    "else:  # ComplexANN\n",
    "    print(\"\\n복잡한 모델이 최적 성능을 보였습니다:\")\n",
    "    print(\"- 데이터가 복잡한 패턴을 가지고 있어 더 깊은 모델이 필요했습니다.\")\n",
    "    print(\"- 드롭아웃이 과적합 방지에 효과적이었습니다.\")\n",
    "\n",
    "# 특성 중요도 분석 (추후 구현)\n",
    "print(\"\\n특성 중요도는 ANN 모델에서 직접 계산하기 어렵습니다.\")\n",
    "print(\"별도의 방법론(예: 순열 중요도, SHAP 값)을 통해 분석할 수 있습니다.\")\n",
    "\n",
    "# 윈도우 크기 분석\n",
    "print(f\"\\n입력 윈도우 크기({WINDOW_SIZE})가 예측 성능에 영향을 미쳤습니다:\")\n",
    "print(f\"- 더 긴 윈도우는 장기 패턴을 포착할 수 있지만 훈련 데이터가 줄어듭니다.\")\n",
    "print(f\"- 더 짧은 윈도우는 최근 패턴에 집중하지만 장기 패턴을 놓칠 수 있습니다.\")\n",
    "\n",
    "# 향후 개선 방향\n",
    "print(\"\\n향후 개선 방향:\")\n",
    "print(\"1. 하이퍼파라미터 최적화를 통한 성능 향상\")\n",
    "print(\"2. 윈도우 크기 및 특성 엔지니어링 조정\")\n",
    "print(\"3. LSTM 등 순환 신경망과의 성능 비교\")\n",
    "print(\"4. 앙상블 방법을 통한 여러 모델 결합\")\n",
    "print(\"5. 미래 예측을 위한 더 정교한 접근법 개발\")\n",
    "\n",
    "print(\"\\n인공신경망 기반 시계열 분석 완료!\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
