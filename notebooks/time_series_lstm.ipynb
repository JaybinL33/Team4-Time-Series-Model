{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09a58c39",
   "metadata": {},
   "source": [
    "# 시계열 분석 - LSTM 모델\n",
    "## Team 4\n",
    "\n",
    "이 노트북은 LSTM(Long Short-Term Memory) 기반 딥러닝 모델을 사용하여 시계열 예측을 수행하는 과정을 보여줍니다.\n",
    "LSTM은 순환 신경망(RNN)의 한 종류로, 시계열 데이터처럼 순서가 중요한 데이터에서 장기 의존성(long-term dependency)을 학습하는 데 강점이 있습니다.\n",
    "과거의 여러 시점 데이터를 입력으로 받아 다음 시점의 값을 예측하는 방식으로 작동합니다.\n",
    "\n",
    "## 분석 흐름\n",
    "1. **문제 정의 및 목표 설정**: 예측 대상과 목표, 평가 지표를 정의합니다.\n",
    "2. **데이터 탐색 및 전처리**: 데이터를 로드하고 시각화하여 패턴을 파악하며, 결측치/이상치를 처리합니다. LSTM 모델링을 위한 특성 엔지니어링, 스케일링, 시퀀스 생성을 수행합니다.\n",
    "3. **모델 선택 및 구현 (LSTM)**: 다양한 구조의 LSTM 모델을 정의하고 컴파일합니다.\n",
    "4. **모델 학습 및 평가**: 정의된 모델들을 학습시키고 검증/테스트 데이터로 성능을 평가합니다. 학습 곡선을 통해 과적합/과소적합 여부를 확인합니다.\n",
    "5. **모델 비교**: 여러 LSTM 모델의 성능을 비교하여 최적 모델을 선정합니다.\n",
    "6. **결과 해석 및 인사이트 도출**: 최적 모델의 예측 결과를 분석하고, 미래 예측 시뮬레이션을 수행하며 인사이트를 도출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe54571",
   "metadata": {},
   "source": [
    "## 1. 문제 정의 및 목표 설정\n",
    "\n",
    "이 템플릿은 LSTM 모델을 사용한 시계열 예측을 위한 기본 구조를 제공합니다.\n",
    "\n",
    "**목표:**\n",
    "- 시계열 데이터의 장기적인 패턴과 복잡한 시간적 의존성을 LSTM 모델로 학습합니다.\n",
    "- 과거 일정 기간(시퀀스)의 데이터를 기반으로 미래 시점의 값을 예측합니다.\n",
    "- 단층, 다층 등 다양한 LSTM 모델 구조를 실험하고 하이퍼파라미터 튜닝을 통해 성능을 비교/개선합니다.\n",
    "\n",
    "**평가 지표:**\n",
    "- RMSE (Root Mean Squared Error): 예측 오차의 제곱 평균 제곱근. 오차의 크기에 민감합니다.\n",
    "- MAE (Mean Absolute Error): 예측 오차 절대값의 평균. 이상치에 덜 민감합니다.\n",
    "- R² Score (Coefficient of Determination): 모델이 데이터의 분산을 얼마나 설명하는지를 나타냅니다. 1에 가까울수록 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c75d8f",
   "metadata": {},
   "source": [
    "### 사용자 파라미터 설정\n",
    "분석 대상 데이터, 모델 구조, 학습 관련 파라미터를 설정합니다.\n",
    "사용자는 자신의 데이터와 분석 목적에 맞게 이 값들을 수정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 파라미터\n",
    "DATA_PATH = \"../data/raw/your_data.csv\"   # 데이터 파일 경로\n",
    "DATE_COL = \"date\"                         # 날짜 컬럼명\n",
    "TARGET_COL = \"value\"                      # 예측할 타겟 컬럼명\n",
    "TRAIN_SIZE = 0.7                          # 훈련 데이터 비율\n",
    "VALIDATION_SIZE = 0.1                     # 검증 데이터 비율 (7:1:2 분할)\n",
    "\n",
    "# 시퀀스 및 모델 파라미터\n",
    "SEQUENCE_LENGTH = 30                      # 시계열 시퀀스 길이 (과거 며칠의 데이터로 예측할지)\n",
    "EPOCHS = 100                              # 최대 학습 에폭\n",
    "BATCH_SIZE = 32                           # 배치 크기\n",
    "PATIENCE = 20                             # 조기 종료 파라미터 (검증 손실 개선이 없을 때 기다릴 에폭 수)\n",
    "FORECAST_HORIZON = 30                     # 미래 예측 기간 (일 단위 등)\n",
    "RANDOM_STATE = 42                         # 랜덤 시드 (재현성을 위해 추가)\n",
    "\n",
    "# 출력 디렉토리\n",
    "OUTPUT_DIR = '../plots'                   # 시각화 결과 저장 경로\n",
    "DATA_OUTPUT_DIR = '../data/processed'     # 전처리된 데이터 저장 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56654ec7",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 임포트\n",
    "데이터 처리, 시각화, 시계열 분석, 딥러닝 모델링(TensorFlow/Keras)에 필요한 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import tensorflow as tf\n",
    "# Keras를 독립 패키지로 사용\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import statsmodels.tsa.api as tsa\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 랜덤 시드 설정 (결과 재현성을 위해)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "keras.utils.set_random_seed(RANDOM_STATE)  # keras 시드 설정 추가\n",
    "\n",
    "# 그래프 스타일 설정\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# 한글 폰트 설정 (한글이 포함된 시각화를 위해, 필요시 활성화)\n",
    "try:\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "except:\n",
    "    print(\"'Malgun Gothic' 폰트가 없습니다. 기본 폰트를 사용합니다.\")\n",
    "\n",
    "# 결과 저장 디렉토리 생성 코드 제거\n",
    "# 프로젝트 지침에 따라 필요 폴더는 이미 존재한다고 가정\n",
    "\n",
    "# # GPU 메모리 설정 (주석 처리됨)\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         print(\"GPU 메모리 증가 설정 완료\")\n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"GPU 설정 오류: {e}\")\n",
    "# else:\n",
    "#     print(\"사용 가능한 GPU가 없습니다. CPU를 사용합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b97fb",
   "metadata": {},
   "source": [
    "## 2. 데이터 탐색 및 전처리\n",
    "모델 학습에 사용할 데이터를 준비하는 과정입니다.\n",
    "데이터 로드, 기본 정보 확인, 결측치/이상치 처리, 시각화를 통한 패턴 분석, 특성 생성, 스케일링, 시퀀스 변환 등을 포함합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28b044",
   "metadata": {},
   "source": [
    "### 2.1 데이터 로드 및 기본 탐색\n",
    "지정된 경로에서 데이터를 로드하고, 날짜 컬럼을 인덱스로 설정하며, 타겟 변수를 확인합니다.\n",
    "데이터의 기본적인 정보(형태, 타입, 통계량)를 출력하여 데이터에 대한 이해를 높입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e26e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 (사용자가 제공한 경로)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"데이터를 성공적으로 로드했습니다. 크기: {df.shape}\")\n",
    "\n",
    "# 날짜 열 처리 (사용자 지정 컬럼 사용)\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "df.set_index(DATE_COL, inplace=True)\n",
    "print(f\"'{DATE_COL}' 열을 인덱스로 설정했습니다.\")\n",
    "\n",
    "# 타겟 변수 확인 (사용자 지정 컬럼 사용)\n",
    "if TARGET_COL not in df.columns:\n",
    "    # TARGET_COL이 없는 경우 오류 발생 또는 경고 후 첫 번째 숫자형 컬럼 사용 등의 처리가 필요하나,\n",
    "    # 템플릿 단순화를 위해 사용자가 올바른 컬럼명을 제공하는 것을 전제합니다.\n",
    "    print(f\"경고: 지정된 타겟 컬럼 '{TARGET_COL}'이 데이터에 없습니다. 첫 번째 숫자형 컬럼을 사용하거나 코드를 수정하세요.\")\n",
    "    # 또는 raise ValueError(f\"Target column '{TARGET_COL}' not found in data.\")\n",
    "\n",
    "print(f\"\\n타겟 변수: {TARGET_COL}\")\n",
    "\n",
    "# 기본 정보 출력\n",
    "print(\"\\n데이터 기본 정보:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n기술 통계량:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 데이터 처음과 끝 확인\n",
    "print(\"\\n데이터 처음 5행:\")\n",
    "print(df.head())\n",
    "print(\"\\n데이터 마지막 5행:\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760add9d",
   "metadata": {},
   "source": [
    "### 2.2 결측치 및 이상치 처리\n",
    "데이터 품질을 확보하기 위해 결측치를 처리하고 이상치를 탐지합니다.\n",
    "- **결측치 처리**: 시계열 데이터의 연속성을 고려하여 보간법(여기서는 시간 기반 선형 보간)을 사용합니다.\n",
    "- **이상치 확인**: 통계적 방법(여기서는 Z-점수)을 사용하여 극단적인 값을 탐지하고 시각화합니다. 시계열 데이터에서는 이상치가 중요한 이벤트일 수 있으므로, 분석 목적에 따라 처리 여부를 신중히 결정해야 합니다. (여기서는 확인만 하고 제거하지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ff07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인\n",
    "print(\"\\n결측치 개수:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 시나리오 A: 결측치가 있는 경우 - 시계열 보간법 적용\n",
    "# 시계열 데이터이므로 시간 기반 보간 방법 사용\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.interpolate(method='time')\n",
    "\n",
    "# 시작/끝에 결측치가 남아있을 경우\n",
    "if df_clean.isnull().sum().sum() > 0:\n",
    "    df_clean = df_clean.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "print(f\"결측치 처리 완료. 남은 결측치: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "# 시나리오 B: 결측치가 없는 경우 (주석 처리됨)\n",
    "# df_clean = df.copy()\n",
    "# print(\"결측치가 없습니다.\")\n",
    "\n",
    "# 이상치 확인 (Z-점수 방법)\n",
    "print(\"\\n이상치 확인 중...\")\n",
    "z_scores = np.abs((df_clean[TARGET_COL] - df_clean[TARGET_COL].mean()) / df_clean[TARGET_COL].std())\n",
    "outliers = (z_scores > 3)\n",
    "\n",
    "# 시나리오 A: 이상치가 있는 경우 - 시각화 및 보존\n",
    "# 시계열 예측에서는 이상치가 실제 중요한 패턴일 수 있으므로 확인만 하고 보존\n",
    "if outliers.any():\n",
    "    print(f\"Z-점수 방법으로 감지된 이상치 개수: {outliers.sum()}\")\n",
    "    \n",
    "    # 이상치 시각화\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.scatter(df_clean.index, df_clean[TARGET_COL], c='blue', alpha=0.5, label='정상 데이터')\n",
    "    plt.scatter(df_clean.index[outliers], df_clean.loc[outliers, TARGET_COL], \n",
    "               c='red', alpha=0.8, label='이상치')\n",
    "    plt.title('시계열 데이터 이상치')\n",
    "    plt.xlabel('날짜')\n",
    "    plt.ylabel(TARGET_COL)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/lstm_이상치.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"이상치는 실제 데이터의 중요한 패턴일 수 있으므로 제거하지 않고 유지합니다.\")\n",
    "else:\n",
    "    print(\"주요 이상치가 감지되지 않았습니다.\")\n",
    "\n",
    "# 시나리오 B: 이상치 처리 - 평균값으로 대체 (주석 처리됨)\n",
    "# 특정 상황에서는 이상치가 모델 성능에 부정적 영향을 줄 수 있어 처리가 필요할 수 있음\n",
    "# if outliers.any():\n",
    "#     print(f\"Z-점수 방법으로 감지된 이상치 개수: {outliers.sum()}\")\n",
    "#     # 이상치를 평균값으로 대체\n",
    "#     df_clean.loc[outliers, TARGET_COL] = df_clean[TARGET_COL].mean()\n",
    "#     print(\"이상치를 평균값으로 대체했습니다.\")\n",
    "# else:\n",
    "#     print(\"주요 이상치가 감지되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0205f72",
   "metadata": {},
   "source": [
    "### 2.3 시계열 시각화 및 패턴 분석\n",
    "전처리된 데이터를 시각화하여 패턴을 분석하고, 정상성 여부를 확인합니다.\n",
    "- **시계열 플롯**: 시간에 따른 데이터 변화 추세를 확인합니다.\n",
    "- **상관관계 히트맵 (다변량 시)**: 여러 특성 간의 선형 상관관계를 확인합니다.\n",
    "- **ACF/PACF 플롯**: 데이터의 자기상관 구조를 파악하여 모델링(특히 ARIMA 계열)에 참고하거나 데이터 특성을 이해합니다.\n",
    "- **ADF 검정**: 시계열의 정상성을 통계적으로 검정합니다. LSTM은 비정상성 데이터도 다룰 수 있지만, 정상성 여부는 데이터 특성 파악에 중요합니다.\n",
    "- **계절성 분해**: 데이터를 추세, 계절성, 잔차로 분해하여 구조적 특징을 파악합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_clean.index, df_clean[TARGET_COL])\n",
    "plt.title('시계열 데이터')\n",
    "plt.xlabel('날짜')\n",
    "plt.ylabel(TARGET_COL)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/lstm_시계열_데이터.png')\n",
    "plt.show()\n",
    "\n",
    "# 다변량 시계열인 경우 상관관계 확인\n",
    "if df_clean.shape[1] > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr = df_clean.corr()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))  # 상삼각행렬만 표시\n",
    "    sns.heatmap(corr, mask=mask, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title('특성 간 상관관계')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/lstm_상관관계_히트맵.png')\n",
    "    plt.show()\n",
    "\n",
    "# ACF, PACF 그래프로 자기상관 분석\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(211)\n",
    "plot_acf(df_clean[TARGET_COL].dropna(), lags=40, ax=plt.gca())\n",
    "plt.title('자기상관함수(ACF)')\n",
    "\n",
    "plt.subplot(212)\n",
    "plot_pacf(df_clean[TARGET_COL].dropna(), lags=40, ax=plt.gca())\n",
    "plt.title('편자기상관함수(PACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/lstm_자기상관.png')\n",
    "plt.show()\n",
    "\n",
    "# ADF 테스트로 정상성 확인\n",
    "adf_result = adfuller(df_clean[TARGET_COL].dropna())\n",
    "print('ADF 테스트 결과:')\n",
    "print(f'ADF 통계값: {adf_result[0]:.4f}')\n",
    "print(f'p-value: {adf_result[1]:.4f}')\n",
    "print('임계값:')\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f'   {key}: {value:.4f}')\n",
    "\n",
    "is_stationary = adf_result[1] < 0.05\n",
    "print(f\"시계열 정상성 여부: {'정상적일 가능성 높음 (p < 0.05)' if is_stationary else '비정상적일 가능성 높음 (p >= 0.05)'}\")\n",
    "\n",
    "# 계절성 분해\n",
    "# 참고: seasonal_decompose는 데이터 길이나 주기 설정에 따라 오류가 발생할 수 있습니다.\n",
    "#      데이터에 맞는 적절한 period 값을 설정해야 합니다. (예: 주간 데이터면 7, 월간 데이터면 12)\n",
    "#      아래는 예시로 period=7을 사용합니다. 실제 데이터에 맞게 수정하세요.\n",
    "decompose_period = 7 # 예시 주기 (필요시 사용자 파라미터로 이동 또는 데이터 기반 설정)\n",
    "decomposition = seasonal_decompose(df_clean[TARGET_COL].dropna(), period=decompose_period)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(411)\n",
    "plt.plot(decomposition.observed)\n",
    "plt.title('관측값')\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.plot(decomposition.trend)\n",
    "plt.title('추세')\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.plot(decomposition.seasonal)\n",
    "plt.title('계절성')\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.plot(decomposition.resid)\n",
    "plt.title('잔차')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/lstm_계절성분해.png')\n",
    "plt.show()\n",
    "print(f\"계절성 분해 완료 (주기: {decompose_period})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8b56f",
   "metadata": {},
   "source": [
    "### 2.4 특성 엔지니어링\n",
    "(선택 사항) LSTM 모델은 원본 시계열 자체를 입력으로 사용할 수도 있지만, 추가적인 특성을 생성하여 모델 성능을 향상시킬 수도 있습니다.\n",
    "여기서는 날짜 관련 특성, 시차 특성, 이동 통계량 특성을 예시로 생성합니다. 분석 대상 데이터와 문제에 따라 유용한 특성은 달라질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ec454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 엔지니어링: 시간 관련 특성 추가\n",
    "# 시나리오 A: 시간 관련 특성과 시차/이동 특성 추가 (DatetimeIndex가 있는 경우)\n",
    "# 목적: 다양한 특성을 모델에 제공하여 시간적 패턴 학습 강화\n",
    "if isinstance(df_clean.index, pd.DatetimeIndex):\n",
    "    print(\"시간 관련 특성 추가 중...\")\n",
    "    # 원본 데이터 복사\n",
    "    df_features = df_clean.copy()\n",
    "    \n",
    "    # 시간 관련 특성\n",
    "    df_features['dayofweek'] = df_features.index.dayofweek\n",
    "    df_features['month'] = df_features.index.month\n",
    "    df_features['year'] = df_features.index.year\n",
    "    df_features['dayofyear'] = df_features.index.dayofyear\n",
    "    df_features['quarter'] = df_features.index.quarter\n",
    "    \n",
    "    # 시간 특성 사인/코사인 변환 (주기성 포착)\n",
    "    df_features['dayofweek_sin'] = np.sin(2 * np.pi * df_features.index.dayofweek / 7)\n",
    "    df_features['dayofweek_cos'] = np.cos(2 * np.pi * df_features.index.dayofweek / 7)\n",
    "    df_features['month_sin'] = np.sin(2 * np.pi * df_features.index.month / 12)\n",
    "    df_features['month_cos'] = np.cos(2 * np.pi * df_features.index.month / 12)\n",
    "    \n",
    "    # 시차 특성 (이전 시점의 값)\n",
    "    df_features['lag_1'] = df_features[TARGET_COL].shift(1)\n",
    "    df_features['lag_7'] = df_features[TARGET_COL].shift(7)\n",
    "    df_features['lag_14'] = df_features[TARGET_COL].shift(14)\n",
    "    \n",
    "    # 이동 평균 및 표준편차\n",
    "    df_features['rolling_mean_7'] = df_features[TARGET_COL].rolling(window=7).mean()\n",
    "    df_features['rolling_std_7'] = df_features[TARGET_COL].rolling(window=7).std()\n",
    "    df_features['rolling_mean_14'] = df_features[TARGET_COL].rolling(window=14).mean()\n",
    "    df_features['rolling_std_14'] = df_features[TARGET_COL].rolling(window=14).std()\n",
    "    \n",
    "    print(\"생성된 특성:\")\n",
    "    print(df_features.columns.tolist())\n",
    "    \n",
    "    # 결측치 처리\n",
    "    df_features = df_features.dropna()\n",
    "    print(f\"특성 생성 완료. 최종 데이터 크기: {df_features.shape}\")\n",
    "    \n",
    "    # 단순 시계열 모델링을 위해 단변량 데이터도 유지\n",
    "    df_univariate = df_clean[[TARGET_COL]].copy()\n",
    "else:\n",
    "    # 시나리오 B: DatetimeIndex가 없는 경우\n",
    "    # 시간 기반 특성 없이 단변량 시계열로 처리\n",
    "    print(\"DatetimeIndex가 없어 단변량 시계열로 처리합니다.\")\n",
    "    df_univariate = df_clean[[TARGET_COL]].copy()\n",
    "    df_features = df_clean.copy()\n",
    "\n",
    "# 시나리오 C: 최소 특성만 사용 (주석 처리됨)\n",
    "# 목적: 모델 복잡성 감소, 더 빠른 훈련 및 예측\n",
    "# df_features = df_clean[[TARGET_COL]].copy()\n",
    "# df_univariate = df_clean[[TARGET_COL]].copy()\n",
    "# print(\"최소 특성 사용 (단변량 시계열)으로 진행합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03cf3e",
   "metadata": {},
   "source": [
    "### 2.5 데이터 스케일링 및 시퀀스 생성\n",
    "딥러닝 모델의 안정적인 학습을 위해 데이터를 특정 범위(여기서는 0~1)로 스케일링하고, LSTM 모델 입력 형식에 맞게 시계열 데이터를 시퀀스 형태로 변환합니다.\n",
    "- **스케일링**: `MinMaxScaler`를 사용하여 모든 특성(및 타겟)을 0과 1 사이로 조정합니다. 다변량 데이터의 경우 각 특성별로 스케일링합니다.\n",
    "- **시퀀스 생성**: `create_sequences` 함수는 원본 시계열을 `SEQUENCE_LENGTH` 길이의 입력 시퀀스(X)와 해당 시퀀스 다음 시점의 타겟 값(y)으로 변환합니다.\n",
    "- **데이터 분할**: 스케일링 및 시퀀스 생성이 완료된 데이터를 훈련, 검증, 테스트 세트로 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11bf5a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "print(\"\\n데이터 스케일링...\")\n",
    "scaler = MinMaxScaler()\n",
    "if len(df_features.columns) > 1:\n",
    "    # 다변량 특성이 있는 경우\n",
    "    target_scaler = MinMaxScaler()\n",
    "    scaled_target = target_scaler.fit_transform(df_features[[TARGET_COL]])\n",
    "    features = df_features.drop(columns=[TARGET_COL])\n",
    "    \n",
    "    # 특성 스케일링\n",
    "    feature_columns = features.columns\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    scaled_features_df = pd.DataFrame(scaled_features, index=df_features.index, columns=feature_columns)\n",
    "    \n",
    "    # 타겟과 특성 결합\n",
    "    scaled_target_df = pd.DataFrame(scaled_target, index=df_features.index, columns=[TARGET_COL])\n",
    "    scaled_df = pd.concat([scaled_target_df, scaled_features_df], axis=1)\n",
    "else:\n",
    "    # 단변량 시계열인 경우\n",
    "    scaled_data = scaler.fit_transform(df_univariate)\n",
    "    scaled_df = pd.DataFrame(scaled_data, index=df_univariate.index, columns=[TARGET_COL])\n",
    "\n",
    "print(f\"스케일링 완료. 데이터 크기: {scaled_df.shape}\")\n",
    "\n",
    "# 시퀀스 생성 함수\n",
    "def create_sequences(data, seq_length, target_col_idx=0):\n",
    "    \"\"\"\n",
    "    시계열 데이터에서 입력 시퀀스와 타겟 값 생성\n",
    "    \n",
    "    Args:\n",
    "        data: 스케일링된 데이터 (numpy 배열)\n",
    "        seq_length: 시퀀스 길이\n",
    "        target_col_idx: 타겟 열의 인덱스\n",
    "        \n",
    "    Returns:\n",
    "        X: 입력 시퀀스의 배열\n",
    "        y: 타겟 값의 배열\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length, target_col_idx]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 데이터 분할\n",
    "print(\"\\n데이터 분할 및 시퀀스 생성...\")\n",
    "train_size = int(len(scaled_df) * TRAIN_SIZE)\n",
    "val_size = int(len(scaled_df) * VALIDATION_SIZE)\n",
    "\n",
    "# 데이터 인덱스 범위 계산\n",
    "train_end = train_size\n",
    "val_end = train_size + val_size\n",
    "test_end = len(scaled_df)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 분할 - 전체 특성 데이터 (7:1:2 비율)\n",
    "train_data = scaled_df.values[:train_end]\n",
    "val_data = scaled_df.values[train_end:val_end]\n",
    "test_data = scaled_df.values[val_end:test_end]\n",
    "\n",
    "# 타겟 열 인덱스 (다변량의 경우 0번째 열이 타겟)\n",
    "target_idx = scaled_df.columns.get_loc(TARGET_COL)\n",
    "\n",
    "# 시퀀스 생성\n",
    "X_train, y_train = create_sequences(train_data, SEQUENCE_LENGTH, target_idx)\n",
    "X_val, y_val = create_sequences(val_data, SEQUENCE_LENGTH, target_idx)\n",
    "X_test, y_test = create_sequences(test_data, SEQUENCE_LENGTH, target_idx)\n",
    "\n",
    "print(f\"훈련 데이터 형태: {X_train.shape}, {y_train.shape} (70%)\")\n",
    "print(f\"검증 데이터 형태: {X_val.shape}, {y_val.shape} (10%)\")\n",
    "print(f\"테스트 데이터 형태: {X_test.shape}, {y_test.shape} (20%)\")\n",
    "\n",
    "# 데이터 분할 시각화 - 원본 값 기준\n",
    "original_dates = df_clean.index\n",
    "train_dates = original_dates[:train_end]\n",
    "val_dates = original_dates[train_end:val_end]\n",
    "test_dates = original_dates[val_end:test_end]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_dates, df_clean.iloc[:train_end][TARGET_COL], label='훈련 데이터 (70%)')\n",
    "plt.plot(val_dates, df_clean.iloc[train_end:val_end][TARGET_COL], label='검증 데이터 (10%)')\n",
    "plt.plot(test_dates, df_clean.iloc[val_end:test_end][TARGET_COL], label='테스트 데이터 (20%)')\n",
    "plt.title('데이터 분할 (7:1:2 비율)')\n",
    "plt.xlabel('날짜')\n",
    "plt.ylabel(TARGET_COL)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/lstm_데이터_분할.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b2180d",
   "metadata": {},
   "source": [
    "## 3. 모델 선택 및 구현\n",
    "LSTM 모델 구조를 정의하고 학습 및 평가를 준비합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fb613",
   "metadata": {},
   "source": [
    "### 3.1 LSTM 모델 정의\n",
    "Keras Sequential API를 사용하여 여러 구조의 LSTM 모델을 정의하는 함수(`build_lstm_model`)를 만듭니다.\n",
    "- **LSTM 레이어**: 시계열 패턴 학습의 핵심 레이어. `units`는 LSTM 셀의 개수, `return_sequences=True`는 다음 LSTM 레이어로 전체 시퀀스를 전달할 때 사용합니다.\n",
    "- **Dropout**: 과적합을 방지하기 위해 일부 뉴런 연결을 무작위로 끊습니다.\n",
    "- **BatchNormalization**: 각 배치마다 입력을 정규화하여 학습을 안정화시키고 속도를 높입니다.\n",
    "- **Dense**: 최종 예측값을 출력하는 완전 연결 레이어.\n",
    "여러 모델 구성(Basic, Medium, Deep)을 리스트로 정의하여 비교 실험을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 정의 함수\n",
    "def build_lstm_model(input_shape, units=64, dropout_rate=0.2, num_layers=2):\n",
    "    \"\"\"\n",
    "    LSTM 모델 생성 함수\n",
    "    \n",
    "    Args:\n",
    "        input_shape: 입력 데이터 형태 (시퀀스 길이, 특성 수)\n",
    "        units: LSTM 유닛(뉴런) 수\n",
    "        dropout_rate: 드롭아웃 비율\n",
    "        num_layers: LSTM 층 수\n",
    "        \n",
    "    Returns:\n",
    "        구성된 LSTM 모델\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 첫 번째 LSTM 층\n",
    "    model.add(LSTM(units=units, \n",
    "                  return_sequences=(num_layers > 1), \n",
    "                  input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 추가 LSTM 층\n",
    "    for i in range(num_layers - 1):\n",
    "        return_seq = i < num_layers - 2  # 마지막 LSTM 층을 제외하고 return_sequences=True\n",
    "        model.add(LSTM(units=units, return_sequences=return_seq))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    # 출력층\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 다양한 LSTM 모델 구성\n",
    "lstm_models = [\n",
    "    {'name': 'LSTM_Basic', 'units': 32, 'dropout_rate': 0.2, 'num_layers': 1},\n",
    "    {'name': 'LSTM_Medium', 'units': 64, 'dropout_rate': 0.3, 'num_layers': 2},\n",
    "    {'name': 'LSTM_Deep', 'units': 128, 'dropout_rate': 0.4, 'num_layers': 3}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9444ce",
   "metadata": {},
   "source": [
    "### 3.2 모델 학습 및 평가 준비\n",
    "모델 학습 과정을 제어하고 성능을 평가하기 위한 준비를 합니다.\n",
    "- **콜백 함수 (Callbacks)**: 모델 학습 중 특정 조건에 따라 추가 작업을 수행합니다.\n",
    "  - `EarlyStopping`: 검증 손실(val_loss)이 일정 에폭(patience) 동안 개선되지 않으면 학습을 조기 종료하여 과적합을 방지하고 최적 가중치를 복원합니다.\n",
    "  - `ReduceLROnPlateau`: 검증 손실 개선이 정체되면 학습률(learning rate)을 동적으로 감소시켜 학습 안정성을 높입니다.\n",
    "- **평가 함수 (evaluate_model)**: 스케일링된 예측값을 원래 스케일로 되돌린 후, RMSE, MAE, R² 등의 성능 지표를 계산하고 예측 결과를 시각화하는 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b2843",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 콜백 함수 설정\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=PATIENCE, \n",
    "        restore_best_weights=True, \n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.5, \n",
    "        patience=PATIENCE//2, \n",
    "        min_lr=0.0001, \n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# 모델 성능 저장 리스트\n",
    "model_performances = []\n",
    "\n",
    "# 모델 평가 함수\n",
    "def evaluate_model(y_true, y_pred, model_name, scaler, dates=None):\n",
    "    \"\"\"\n",
    "    모델 성능 평가 함수\n",
    "    \n",
    "    Args:\n",
    "        y_true: 실제 값\n",
    "        y_pred: 예측 값\n",
    "        model_name: 모델 이름\n",
    "        scaler: 데이터 스케일러\n",
    "        dates: 예측 날짜 (선택 사항)\n",
    "        \n",
    "    Returns:\n",
    "        rmse, mae, r2: 평가 지표\n",
    "        y_pred_orig: 원래 스케일로 변환된 예측 값\n",
    "    \"\"\"\n",
    "    # 예측값을 원래 스케일로 변환\n",
    "    y_true_reshaped = y_true.reshape(-1, 1)\n",
    "    y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "    \n",
    "    # 원래 데이터가 단변량이었을 경우\n",
    "    if len(scaled_df.columns) == 1:\n",
    "        y_true_orig = scaler.inverse_transform(y_true_reshaped).flatten()\n",
    "        y_pred_orig = scaler.inverse_transform(y_pred_reshaped).flatten()\n",
    "    else:\n",
    "        # 다변량인 경우, 타겟 변수의 스케일러만 사용\n",
    "        # 임시 데이터프레임에 같은 크기로 복사 후 역변환\n",
    "        temp_true = np.zeros((len(y_true), scaled_df.shape[1]))\n",
    "        temp_true[:, target_idx] = y_true\n",
    "        \n",
    "        temp_pred = np.zeros((len(y_pred), scaled_df.shape[1]))\n",
    "        temp_pred[:, target_idx] = y_pred\n",
    "        \n",
    "        y_true_orig = scaler.inverse_transform(temp_true)[:, target_idx]\n",
    "        y_pred_orig = scaler.inverse_transform(temp_pred)[:, target_idx]\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
    "    mae = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    r2 = r2_score(y_true_orig, y_pred_orig)\n",
    "    \n",
    "    print(f\"\\n{model_name} 모델 성능 지표:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    \n",
    "    # 시각화 (날짜가 제공된 경우)\n",
    "    if dates is not None:\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(dates, y_true_orig, label='실제값')\n",
    "        plt.plot(dates, y_pred_orig, label='예측값', alpha=0.7)\n",
    "        plt.title(f'{model_name} - 예측 결과')\n",
    "        plt.xlabel('날짜')\n",
    "        plt.ylabel(TARGET_COL)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/lstm_{model_name}_예측.png')\n",
    "        plt.show()\n",
    "    \n",
    "    return rmse, mae, r2, y_pred_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f20e6e",
   "metadata": {},
   "source": [
    "### 3.3 모델 학습 및 평가\n",
    "정의된 각 LSTM 모델 구성에 대해 다음 과정을 반복합니다:\n",
    "1. 모델 생성 (`build_lstm_model` 호출)\n",
    "2. 모델 아키텍처 확인 (`model.summary()`)\n",
    "3. 모델 학습 (`model.fit()`): 훈련 데이터(X_train, y_train)로 학습하고, 검증 데이터(X_val, y_val)로 에폭별 성능을 모니터링합니다. 설정된 콜백 함수들이 적용됩니다.\n",
    "4. 학습 곡선 시각화: 에폭별 훈련 손실과 검증 손실을 그래프로 그려 과적합/과소적합 여부를 확인합니다.\n",
    "5. 검증/테스트 데이터 예측 및 평가 (`evaluate_model` 호출): 학습된 모델로 검증 및 테스트 데이터에 대한 예측을 수행하고 성능 지표를 계산 및 시각화합니다.\n",
    "6. 성능 결과 저장: 각 모델의 성능 지표를 리스트(`model_performances`)에 저장합니다.\n",
    "7. 모델 저장 (선택 사항): 학습된 모델 가중치를 파일(`.h5`)로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 모델 학습 및 평가\n",
    "for model_config in lstm_models:\n",
    "    model_name = model_config['name']\n",
    "    print(f\"\\n{model_name} 모델 학습 시작...\")\n",
    "    \n",
    "    # 모델 생성\n",
    "    model = build_lstm_model(\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        units=model_config['units'],\n",
    "        dropout_rate=model_config['dropout_rate'],\n",
    "        num_layers=model_config['num_layers']\n",
    "    )\n",
    "    \n",
    "    # 모델 아키텍처 출력\n",
    "    model.summary()\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 학습 곡선 시각화\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(history.history['loss'], label='훈련 손실')\n",
    "    plt.plot(history.history['val_loss'], label='검증 손실')\n",
    "    plt.title(f'{model_name} - 학습 곡선')\n",
    "    plt.xlabel('에폭')\n",
    "    plt.ylabel('손실 (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/lstm_{model_name}_학습곡선.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # 검증 데이터 예측\n",
    "    val_pred = model.predict(X_val)\n",
    "    # 검증 데이터에 해당하는 날짜 (시퀀스 길이만큼 이동)\n",
    "    val_dates = val_dates[SEQUENCE_LENGTH:]\n",
    "    \n",
    "    # 검증 데이터 평가\n",
    "    val_rmse, val_mae, val_r2, val_pred_orig = evaluate_model(\n",
    "        y_val, val_pred, f\"{model_name} (검증)\", scaler, val_dates\n",
    "    )\n",
    "    \n",
    "    # 테스트 데이터 예측\n",
    "    test_pred = model.predict(X_test)\n",
    "    # 테스트 데이터에 해당하는 날짜 (시퀀스 길이만큼 이동)\n",
    "    test_dates = test_dates[SEQUENCE_LENGTH:]\n",
    "    \n",
    "    # 테스트 데이터 평가\n",
    "    test_rmse, test_mae, test_r2, test_pred_orig = evaluate_model(\n",
    "        y_test, test_pred, f\"{model_name} (테스트)\", scaler, test_dates\n",
    "    )\n",
    "    \n",
    "    # 성능 저장\n",
    "    model_performances.append({\n",
    "        'model': model_name,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_mae': val_mae,\n",
    "        'val_r2': val_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'test_r2': test_r2\n",
    "    })\n",
    "    \n",
    "    # 모델 저장 (선택 사항)\n",
    "    model.save(f'{DATA_OUTPUT_DIR}/lstm_{model_name}.h5')\n",
    "    print(f\"{model_name} 모델이 '{DATA_OUTPUT_DIR}/lstm_{model_name}.h5'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31720623",
   "metadata": {},
   "source": [
    "## 4. 모델 평가 및 비교\n",
    "여러 LSTM 모델들의 성능 평가 결과를 종합하고 비교합니다.\n",
    "- **성능 비교 테이블**: 각 모델의 검증 및 테스트 성능 지표를 Pandas DataFrame으로 정리하여 출력합니다.\n",
    "- **성능 비교 시각화**: 주요 성능 지표(RMSE, R²)를 막대 그래프로 시각화하여 모델 간 성능 차이를 직관적으로 비교합니다.\n",
    "- **최고 성능 모델 선택**: 테스트 RMSE가 가장 낮은 모델을 최적 모델로 선정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea46726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능 비교 테이블\n",
    "models_comparison = pd.DataFrame([\n",
    "    {\n",
    "        '모델': m['model'],\n",
    "        'RMSE (검증)': m['val_rmse'],\n",
    "        'MAE (검증)': m['val_mae'],\n",
    "        'R² (검증)': m['val_r2'],\n",
    "        'RMSE (테스트)': m['test_rmse'],\n",
    "        'MAE (테스트)': m['test_mae'],\n",
    "        'R² (테스트)': m['test_r2']\n",
    "    }\n",
    "    for m in model_performances\n",
    "])\n",
    "\n",
    "print(\"\\n모델 성능 비교:\")\n",
    "print(models_comparison)\n",
    "\n",
    "# 모델 비교 결과 저장\n",
    "models_comparison.to_csv(f'{DATA_OUTPUT_DIR}/lstm_모델비교_결과.csv', index=False)\n",
    "print(f\"모델 비교 결과가 '{DATA_OUTPUT_DIR}/lstm_모델비교_결과.csv'에 저장되었습니다.\")\n",
    "\n",
    "# 모델 비교 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(121)\n",
    "sns.barplot(x='모델', y='RMSE (테스트)', data=models_comparison)\n",
    "plt.title('LSTM 모델 비교 - RMSE (낮을수록 좋음)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.barplot(x='모델', y='R² (테스트)', data=models_comparison)\n",
    "plt.title('LSTM 모델 비교 - R² (높을수록 좋음)')\n",
    "plt.ylabel('R²')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/lstm_모델비교.png')\n",
    "plt.show()\n",
    "\n",
    "# 최고 성능 모델 선택\n",
    "best_model_idx = models_comparison['RMSE (테스트)'].idxmin()\n",
    "best_model = models_comparison.iloc[best_model_idx]['모델']\n",
    "best_rmse = models_comparison.iloc[best_model_idx]['RMSE (테스트)']\n",
    "best_r2 = models_comparison.iloc[best_model_idx]['R² (테스트)']\n",
    "\n",
    "print(f\"\\n최고 성능 모델: {best_model}\")\n",
    "print(f\"테스트 RMSE: {best_rmse:.4f}\")\n",
    "print(f\"테스트 R²: {best_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ca92e",
   "metadata": {},
   "source": [
    "## 5. 결과 해석 및 인사이트 도출\n",
    "최종 선정된 최적 모델의 성능을 바탕으로 결과를 해석하고, 미래 예측을 수행하며 인사이트를 도출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f6494",
   "metadata": {},
   "source": [
    "### 5.1 미래 예측 시뮬레이션\n",
    "최적 모델을 사용하여 학습 데이터 이후의 미래 기간(`FORECAST_HORIZON`)에 대한 예측을 수행합니다.\n",
    "여기서는 **반복적 예측(Iterative Forecasting)** 방식을 사용합니다:\n",
    "1. 가장 마지막 시퀀스 데이터를 초기 입력으로 사용합니다.\n",
    "2. 다음 한 스텝의 값을 예측합니다.\n",
    "3. 예측된 값을 다음 입력 시퀀스에 포함시키고, 가장 오래된 값을 제거하여 시퀀스를 업데이트합니다.\n",
    "4. 위 과정을 예측하려는 기간만큼 반복합니다.\n",
    "최종 예측값은 원래 스케일로 변환하여 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미래 예측을 위한 예시\n",
    "print(\"\\n미래 예측 시뮬레이션\")\n",
    "print(\"실제 프로젝트에서는 이 부분을 데이터에 맞게 수정해야 합니다.\")\n",
    "\n",
    "# 최상의 모델 로드\n",
    "best_model_config = next(m for m in lstm_models if m['name'] == best_model)\n",
    "best_model_loaded = keras.models.load_model(f'{DATA_OUTPUT_DIR}/lstm_{best_model}.h5')  # keras로 수정\n",
    "\n",
    "# 예측 기간 설정 (파라미터 사용)\n",
    "forecast_horizon = FORECAST_HORIZON\n",
    "\n",
    "# 예측을 위한 마지막 시퀀스 가져오기\n",
    "# (실제 프로젝트에서는 아래 로직을 데이터에 맞게 수정해야 함)\n",
    "last_sequence = scaled_df.values[-SEQUENCE_LENGTH:].reshape(1, SEQUENCE_LENGTH, scaled_df.shape[1])\n",
    "\n",
    "# 미래 날짜 생성\n",
    "last_date = df_clean.index[-1]\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=forecast_horizon)\n",
    "\n",
    "# 점진적 예측 (이전 예측을 다음 입력으로 사용)\n",
    "predictions = []\n",
    "current_sequence = last_sequence.copy()\n",
    "\n",
    "for _ in range(forecast_horizon):\n",
    "    # 다음 값 예측\n",
    "    next_pred = best_model_loaded.predict(current_sequence)[0][0]\n",
    "    predictions.append(next_pred)\n",
    "    \n",
    "    # 시퀀스 업데이트 (가장 오래된 값 제거하고 새 예측값 추가)\n",
    "    new_values = current_sequence[0, 1:, :].copy()\n",
    "    \n",
    "    # 다변량인 경우, 타겟 열만 업데이트\n",
    "    if scaled_df.shape[1] > 1:\n",
    "        # 값 복사\n",
    "        new_row = current_sequence[0, -1, :].copy()\n",
    "        # 타겟 열만 새 예측으로 업데이트\n",
    "        new_row[target_idx] = next_pred\n",
    "        # 새 행 추가\n",
    "        new_values = np.vstack([new_values, new_row.reshape(1, -1)])\n",
    "    else:\n",
    "        # 단변량인 경우, 단순히 새 예측값 추가\n",
    "        new_values = np.vstack([new_values, np.array([[next_pred]])])\n",
    "    \n",
    "    # 업데이트된 시퀀스로 교체\n",
    "    current_sequence[0] = new_values\n",
    "\n",
    "# 예측 역변환\n",
    "if scaled_df.shape[1] == 1:\n",
    "    # 단변량 케이스\n",
    "    predictions_array = np.array(predictions).reshape(-1, 1)\n",
    "    predictions_original = scaler.inverse_transform(predictions_array).flatten()\n",
    "else:\n",
    "    # 다변량 케이스 (타겟 변수만 역변환)\n",
    "    temp_array = np.zeros((len(predictions), scaled_df.shape[1]))\n",
    "    temp_array[:, target_idx] = predictions\n",
    "    predictions_original = scaler.inverse_transform(temp_array)[:, target_idx]\n",
    "\n",
    "# 예측 결과 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "# 과거 데이터 (마지막 90일)\n",
    "history_days = 90\n",
    "past_dates = df_clean.index[-history_days:]\n",
    "past_values = df_clean[TARGET_COL][-history_days:]\n",
    "\n",
    "plt.plot(past_dates, past_values, label='과거 데이터', color='blue')\n",
    "plt.plot(future_dates, predictions_original, label='미래 예측', color='red', linestyle='--')\n",
    "plt.axvline(x=last_date, color='green', linestyle='-', label='현재')\n",
    "plt.title(f'{best_model} - {FORECAST_HORIZON}일 미래 예측')\n",
    "plt.xlabel('날짜')\n",
    "plt.ylabel(TARGET_COL)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/lstm_미래예측.png')\n",
    "plt.show()\n",
    "\n",
    "# 예측 결과를 DataFrame으로 변환\n",
    "forecast_df = pd.DataFrame({\n",
    "    'date': future_dates,\n",
    "    f'{TARGET_COL}_forecast': predictions_original\n",
    "})\n",
    "\n",
    "print(\"\\n미래 예측 결과 (처음 10일):\")\n",
    "print(forecast_df.head(10))\n",
    "\n",
    "# 예측 결과 저장\n",
    "forecast_df.to_csv(f'{DATA_OUTPUT_DIR}/lstm_forecast_results.csv', index=False)\n",
    "print(f\"예측 결과가 '{DATA_OUTPUT_DIR}/lstm_forecast_results.csv'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cfab36",
   "metadata": {},
   "source": [
    "### 5.2 결론 및 인사이트\n",
    "전체 분석 과정과 모델 성능 결과를 요약합니다.\n",
    "- 최적 모델과 그 성능(RMSE, R²)을 명시합니다.\n",
    "- 최적 모델의 구성(units, dropout, layers)을 제시합니다.\n",
    "- 모델 성능에 영향을 미친 요인(모델 복잡성, 시퀀스 길이, 데이터 정상성 등)에 대한 간략한 해석을 제공합니다.\n",
    "- 향후 모델 성능 개선을 위한 방향(하이퍼파라미터 튜닝, 특성 추가, 다른 모델 구조 시도 등)을 제안합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07579e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"결론 및 인사이트\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 모델 성능 요약\n",
    "print(f\"1. 최적의 모델: {best_model}\")\n",
    "print(f\"2. 테스트 RMSE: {best_rmse:.4f}\")\n",
    "print(f\"3. 테스트 R²: {best_r2:.4f}\")\n",
    "\n",
    "# 모델 구성 요약\n",
    "print(\"\\n최적 모델 구성:\")\n",
    "for key, value in best_model_config.items():\n",
    "    if key != 'name':\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "# 주요 인사이트\n",
    "print(\"\\n주요 인사이트:\")\n",
    "print(\"1. LSTM 모델의 복잡성과 성능 간의 균형\")\n",
    "if best_model == 'LSTM_Basic':\n",
    "    print(\"   - 단순한 모델이 가장 우수한 성능을 보였으며, 과적합 위험이 낮았습니다.\")\n",
    "elif best_model == 'LSTM_Medium':\n",
    "    print(\"   - 중간 복잡도의 모델이 가장 우수한 성능을 보였으며, 단순 모델보다 패턴 포착에 효과적이었습니다.\")\n",
    "else:\n",
    "    print(\"   - 복잡한 모델이 데이터 패턴을 잘 포착하여 더 좋은 성능을 보였습니다.\")\n",
    "\n",
    "print(\"2. 시퀀스 길이의 영향\")\n",
    "print(f\"   - {SEQUENCE_LENGTH}일의 시퀀스 길이로 예측에 성공했으며, 이는 데이터의 기본 패턴 주기와 관련이 있습니다.\")\n",
    "\n",
    "print(\"3. 정상성과 모델 성능\")\n",
    "if is_stationary:\n",
    "    print(\"   - 데이터가 정상성을 보여 모델 학습이 더 안정적이었습니다.\")\n",
    "else:\n",
    "    print(\"   - 데이터의 비정상성에도 불구하고 LSTM이 패턴을 학습할 수 있었습니다.\")\n",
    "\n",
    "# 향후 개선 방향\n",
    "print(\"\\n향후 개선 방향:\")\n",
    "print(\"1. 시퀀스 길이 최적화를 통한 성능 향상 가능\")\n",
    "print(\"2. 더 다양한 특성 엔지니어링 시도\")\n",
    "print(\"3. 양방향 LSTM 또는 Attention 메커니즘 적용 고려\")\n",
    "print(\"4. 앙상블 방법을 통한 여러 모델 결합\")\n",
    "print(\"5. 예측 불확실성 추정 방법 도입\")\n",
    "\n",
    "print(\"\\nLSTM 기반 시계열 분석 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b124e",
   "metadata": {},
   "source": [
    "## 6. 시계열 교차 검증 (Time Series Cross-Validation)\n",
    "본 분석에서는 기본적인 훈련/검증/테스트 분할 방식을 사용했습니다. 더 견고한 모델 평가를 위해 시계열 교차 검증을 추가로 수행합니다.\n",
    "시계열 데이터에서는 일반적인 k-fold 교차 검증이 아닌, 시간적 의존성을 고려한 `TimeSeriesSplit`을 사용합니다.\n",
    "LSTM 모델은 계산 비용이 높아 간소화된 모델로 교차 검증을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 교차 검증 설정\n",
    "print(\"\\n시계열 교차 검증 수행 중...\")\n",
    "n_splits = 3  # LSTM은 계산 비용이 높으므로 fold 수를 줄임\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# 교차 검증을 위한 간소화된 모델 생성 함수\n",
    "def build_simple_lstm_for_cv(input_shape):\n",
    "    \"\"\"교차 검증용 간소화된 LSTM 모델\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(32, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# 모든 데이터 (스케일링된)를 하나로 합치기\n",
    "all_data = np.vstack([train_data, val_data, test_data])\n",
    "\n",
    "# 결과 저장\n",
    "cv_rmse_scores = []\n",
    "cv_mae_scores = []\n",
    "\n",
    "# 교차 검증 시각화 준비\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# 각 폴드에 대해 학습 및 평가\n",
    "for i, (train_idx, test_idx) in enumerate(tscv.split(all_data)):\n",
    "    print(f\"\\nFold {i+1}/{n_splits} 처리 중...\")\n",
    "    \n",
    "    # 훈련/테스트 데이터 분할\n",
    "    cv_train_data = all_data[train_idx]\n",
    "    cv_test_data = all_data[test_idx]\n",
    "    \n",
    "    # 시퀀스 생성\n",
    "    cv_X_train, cv_y_train = create_sequences(cv_train_data, SEQUENCE_LENGTH, target_idx)\n",
    "    cv_X_test, cv_y_test = create_sequences(cv_test_data, SEQUENCE_LENGTH, target_idx)\n",
    "    \n",
    "    # 간소화된 모델 구축 및 학습\n",
    "    cv_model = build_simple_lstm_for_cv(cv_X_train.shape[1:])\n",
    "    cv_model.fit(\n",
    "        cv_X_train, cv_y_train,\n",
    "        epochs=20,  # 빠른 학습을 위해 에포크 감소\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 예측\n",
    "    cv_y_pred = cv_model.predict(cv_X_test)\n",
    "    \n",
    "    # 원래 스케일로 변환 (스케일러를 이미 알고 있다고 가정)\n",
    "    # 실제 구현에서는 각 분할마다 스케일러를 따로 생성해야 할 수 있음\n",
    "    cv_y_test_orig = scaler.inverse_transform(np.hstack([cv_X_test[:, -1, :], cv_y_test.reshape(-1, 1)]))[:, -1]\n",
    "    cv_y_pred_orig = scaler.inverse_transform(np.hstack([cv_X_test[:, -1, :], cv_y_pred.reshape(-1, 1)]))[:, -1]\n",
    "    \n",
    "    # 성능 평가\n",
    "    cv_rmse = np.sqrt(mean_squared_error(cv_y_test_orig, cv_y_pred_orig))\n",
    "    cv_mae = mean_absolute_error(cv_y_test_orig, cv_y_pred_orig)\n",
    "    cv_rmse_scores.append(cv_rmse)\n",
    "    cv_mae_scores.append(cv_mae)\n",
    "    \n",
    "    # 각 폴드의 결과 출력\n",
    "    print(f\"Fold {i+1} - RMSE: {cv_rmse:.4f}, MAE: {cv_mae:.4f}\")\n",
    "    \n",
    "    # 시각화 (최대 30개 포인트만)\n",
    "    plt.subplot(n_splits, 1, i+1)\n",
    "    vis_limit = min(30, len(cv_y_test_orig))\n",
    "    plt.plot(cv_y_test_orig[:vis_limit], label='실제값')\n",
    "    plt.plot(cv_y_pred_orig[:vis_limit], label='예측값', linestyle='--')\n",
    "    plt.title(f'Fold {i+1} - RMSE: {cv_rmse:.4f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/lstm_교차검증.png')\n",
    "plt.show()\n",
    "\n",
    "# 교차 검증 결과 요약\n",
    "print(\"\\n교차 검증 결과:\")\n",
    "print(f\"평균 RMSE: {np.mean(cv_rmse_scores):.4f} (±{np.std(cv_rmse_scores):.4f})\")\n",
    "print(f\"평균 MAE: {np.mean(cv_mae_scores):.4f} (±{np.std(cv_mae_scores):.4f})\")\n",
    "\n",
    "# 교차 검증 성능 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(cv_rmse_scores)), cv_rmse_scores, alpha=0.7, label='RMSE')\n",
    "plt.bar(range(len(cv_mae_scores)), cv_mae_scores, alpha=0.5, label='MAE')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('오차')\n",
    "plt.title('교차 검증 성능')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(f'{OUTPUT_DIR}/lstm_교차검증_성능.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
